{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 便利店销量预测\n",
    "这是[便利店销量预测比赛](https://www.kaggle.com/c/rossmann-store-sales)的一个简单尝试参考。<br>\n",
    "by [@寒小阳](http://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"page-name\">\n",
    "    Forecast sales using store, promotion, and competitor data\n",
    "</h1>\n",
    "\n",
    "\n",
    "<p>Rossmann operates over 3,000 drug stores in 7 European countries. Currently, <br />Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.</p>\n",
    "<p><span style=\"font-size: 1em; line-height: 1.5em;\">In their first Kaggle competition, Rossmann is challenging you to predict 6 weeks of daily sales for 1,115 stores located across Germany. Reliable sales forecasts enable store managers to create effective staff schedules that increase productivity and motivation. By helping Rossmann create a robust prediction model, you will help store managers stay focused on what’s most important to them: their customers and their teams! </span></p>\n",
    "<p><span style=\"font-size: 1em; line-height: 1.5em;\"> <img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/4594/media/rossmann_banner2.png\" alt=\"\" height=\"81\" width=\"640\" /><br /></span></p>\n",
    "<p><em><span style=\"font-size: 1em; line-height: 1.5em;\">If you are interested in joining Rossmann at their headquarters near Hanover, Germany, please contact Mr. Frank König (Frank.Koenig {at} rossmann.de) Rossmann is currently recruiting data scientists at <a href=\"http://www.rossmann.de/unternehmen/karriere/stellenboerse/stellenanzeigen~jid=3A5205E3-C4F9-4F5D-AA93-438D0B064D70~\">senior</a> and <a href=\"http://www.rossmann.de/unternehmen/karriere/stellenboerse/stellenanzeigen~jid=F5142F37-C823-4767-B7CF-21DE3B351D66~\">entry-level</a> positions.</span></em></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据\n",
    "<table id=\"data-files\" class=\"nicetable full roomy align-top border\">   \n",
    "<thead>\n",
    "    <tr>\n",
    "        <th colspan=\"2\">File Name</th> \n",
    "        <th>Available Formats</th>         \n",
    "    </tr> \n",
    "</thead>\n",
    "\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">sample_submission.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/sample_submission.csv.zip\" name=\"sample_submission.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (55.25 kb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">store.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/store.csv.zip\" name=\"store.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (8.33 kb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">test.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/test.csv.zip\" name=\"test.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (143.25 kb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">train.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/train.csv.zip\" name=\"train.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (5.66 mb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Files</h3>\n",
    "<ul>\n",
    "<li><strong>train.csv</strong> - historical data including Sales</li>\n",
    "<li><strong>test.csv</strong> - historical data excluding Sales</li>\n",
    "<li><strong>sample_submission.csv</strong> - a sample submission file in the correct format</li>\n",
    "<li><strong>store.csv</strong> - supplemental information about the stores</li>\n",
    "</ul>\n",
    "<h3>Data fields</h3>\n",
    "<p>Most of the fields are self-explanatory. The following are descriptions for those that aren't.</p>\n",
    "<ul>\n",
    "<li><strong>Id</strong> - an Id that represents a (Store, Date) duple within the test set</li>\n",
    "<li><strong>Store</strong> - a unique Id for each store</li>\n",
    "<li><strong>Sales</strong> - the turnover for any given day (this is what you are predicting)</li>\n",
    "<li><strong>Customers</strong> - the number of customers on a given day</li>\n",
    "<li><strong>Open</strong> - an indicator for whether the store was open: 0 = closed, 1 = open</li>\n",
    "<li><strong>StateHoliday</strong> - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None</li>\n",
    "<li><strong>SchoolHoliday</strong> - indicates if the (Store, Date) was affected by the closure of public schools</li>\n",
    "<li><strong>StoreType</strong> - differentiates between 4 different store models: a, b, c, d</li>\n",
    "<li><strong>Assortment</strong> - describes an assortment level: a = basic, b = extra, c = extended</li>\n",
    "<li><strong>CompetitionDistance</strong> - distance in meters to the nearest competitor store</li>\n",
    "<li><strong>CompetitionOpenSince[Month/Year]</strong> - gives the approximate year and month of the time the nearest competitor was opened</li>\n",
    "<li><strong>Promo</strong> - indicates whether a store is running a promo on that day</li>\n",
    "<li><strong>Promo2</strong> - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating</li>\n",
    "<li><strong>Promo2Since[Year/Week]</strong> - describes the year and calendar week when the store started participating in Promo2</li>\n",
    "<li><strong>PromoInterval</strong> - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入所需的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy as sp\n",
    "import xgboost as xgb\n",
    "import itertools\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import cross_validation\n",
    "from matplotlib import pylab as plt\n",
    "plot = True\n",
    "\n",
    "goal = 'Sales'\n",
    "myid = 'Id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当你的eval metric和loss function并不一致的时候\n",
    "\n",
    "### Early stopping\n",
    "按照原来的loss function去优化，一颗一颗树生长和添加，但是在验证集上，盯着eval metric去看，在验证集上评估指标不再优化的时候，停止集成模型的生长。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有标签的数据部分(训练集) + 无标签/需要做预估的部分(测试集)<br>\n",
    "训练集 = 真正的训练集 + 验证集(利用它去完成模型选择和调参)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义一些变换和评判准则\n",
    "使用不同的evaluation function的时候要特别注意这个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ToWeight(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "def rmspe(yhat, y):\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n",
    "    return rmspe\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    # y = y.values\n",
    "    y = y.get_label()\n",
    "    y = np.exp(y) - 1\n",
    "    yhat = np.exp(yhat) - 1\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n",
    "    return \"rmspe\", rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.read_csv('store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>620.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
       "0      1         c          a               1270.0                        9.0   \n",
       "1      2         a          a                570.0                       11.0   \n",
       "2      3         a          a              14130.0                       12.0   \n",
       "3      4         c          c                620.0                        9.0   \n",
       "4      5         a          a              29910.0                        4.0   \n",
       "\n",
       "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
       "0                    2008.0       0              NaN              NaN   \n",
       "1                    2007.0       1             13.0           2010.0   \n",
       "2                    2006.0       1             14.0           2011.0   \n",
       "3                    2009.0       0              NaN              NaN   \n",
       "4                    2015.0       0              NaN              NaN   \n",
       "\n",
       "     PromoInterval  \n",
       "0              NaN  \n",
       "1  Jan,Apr,Jul,Oct  \n",
       "2  Jan,Apr,Jul,Oct  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          5  2015-07-31   5263        555     1      1            0   \n",
       "1      2          5  2015-07-31   6064        625     1      1            0   \n",
       "2      3          5  2015-07-31   8314        821     1      1            0   \n",
       "3      4          5  2015-07-31  13995       1498     1      1            0   \n",
       "4      5          5  2015-07-31   4822        559     1      1            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Store  DayOfWeek        Date  Open  Promo StateHoliday  SchoolHoliday\n",
       "0   1      1          4  2015-09-17   1.0      1            0              0\n",
       "1   2      3          4  2015-09-17   1.0      1            0              0\n",
       "2   3      7          4  2015-09-17   1.0      1            0              0\n",
       "3   4      8          4  2015-09-17   1.0      1            0              0\n",
       "4   5      9          4  2015-09-17   1.0      1            0              0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "        加载数据，设定数值型和非数值型数据\n",
    "    \"\"\"\n",
    "    store = pd.read_csv('store.csv')\n",
    "    train_org = pd.read_csv('train.csv',dtype={'StateHoliday':pd.np.string_})\n",
    "    test_org = pd.read_csv('test.csv',dtype={'StateHoliday':pd.np.string_})\n",
    "    train = pd.merge(train_org,store, on='Store', how='left')\n",
    "    test = pd.merge(test_org,store, on='Store', how='left')\n",
    "    features = test.columns.tolist()\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    features_numeric = test.select_dtypes(include=numerics).columns.tolist()\n",
    "    features_non_numeric = [f for f in features if f not in features_numeric]\n",
    "    return (train,test,features,features_non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据与特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(train,test,features,features_non_numeric):\n",
    "    \"\"\"\n",
    "        Feature engineering and selection.\n",
    "    \"\"\"\n",
    "    # # FEATURE ENGINEERING\n",
    "    train = train[train['Sales'] > 0]\n",
    "\n",
    "    for data in [train,test]:\n",
    "        # year month day\n",
    "        data['year'] = data.Date.apply(lambda x: x.split('-')[0])\n",
    "        data['year'] = data['year'].astype(float)\n",
    "        data['month'] = data.Date.apply(lambda x: x.split('-')[1])\n",
    "        data['month'] = data['month'].astype(float)\n",
    "        data['day'] = data.Date.apply(lambda x: x.split('-')[2])\n",
    "        data['day'] = data['day'].astype(float)\n",
    "\n",
    "        # promo interval \"Jan,Apr,Jul,Oct\"\n",
    "        data['promojan'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Jan\" in x else 0)\n",
    "        data['promofeb'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Feb\" in x else 0)\n",
    "        data['promomar'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Mar\" in x else 0)\n",
    "        data['promoapr'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Apr\" in x else 0)\n",
    "        data['promomay'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"May\" in x else 0)\n",
    "        data['promojun'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Jun\" in x else 0)\n",
    "        data['promojul'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Jul\" in x else 0)\n",
    "        data['promoaug'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Aug\" in x else 0)\n",
    "        data['promosep'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Sep\" in x else 0)\n",
    "        data['promooct'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Oct\" in x else 0)\n",
    "        data['promonov'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Nov\" in x else 0)\n",
    "        data['promodec'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Dec\" in x else 0)\n",
    "\n",
    "    # # Features set.\n",
    "    noisy_features = [myid,'Date']\n",
    "    features = [c for c in features if c not in noisy_features]\n",
    "    features_non_numeric = [c for c in features_non_numeric if c not in noisy_features]\n",
    "    features.extend(['year','month','day'])\n",
    "    # Fill NA\n",
    "    class DataFrameImputer(TransformerMixin):\n",
    "        # http://stackoverflow.com/questions/25239958/impute-categorical-missing-values-in-scikit-learn\n",
    "        def __init__(self):\n",
    "            \"\"\"Impute missing values.\n",
    "            Columns of dtype object are imputed with the most frequent value\n",
    "            in column.\n",
    "            Columns of other types are imputed with mean of column.\n",
    "            \"\"\"\n",
    "        def fit(self, X, y=None):\n",
    "            self.fill = pd.Series([X[c].value_counts().index[0] # mode\n",
    "                if X[c].dtype == np.dtype('O') else X[c].mean() for c in X], # mean\n",
    "                index=X.columns)\n",
    "            return self\n",
    "        def transform(self, X, y=None):\n",
    "            return X.fillna(self.fill)\n",
    "    train = DataFrameImputer().fit_transform(train)\n",
    "    test = DataFrameImputer().fit_transform(test)\n",
    "    # Pre-processing non-numberic values\n",
    "    le = LabelEncoder()\n",
    "    for col in features_non_numeric:\n",
    "        le.fit(list(train[col])+list(test[col]))\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])\n",
    "    # LR和神经网络这种模型都对输入数据的幅度极度敏感，请先做归一化操作\n",
    "    scaler = StandardScaler()\n",
    "    for col in set(features) - set(features_non_numeric) - \\\n",
    "      set([]): # TODO: add what not to scale\n",
    "        scaler.fit(list(train[col])+list(test[col]))\n",
    "        train[col] = scaler.transform(train[col])\n",
    "        test[col] = scaler.transform(test[col])\n",
    "    return (train,test,features,features_non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练与分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "predict_result = log(y+1)\n",
    "y = e^(predict_result)-1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def XGB_native(train,test,features,features_non_numeric):\n",
    "    depth = 6\n",
    "    eta = 0.01\n",
    "    ntrees = 8000\n",
    "    mcw = 3\n",
    "    params = {\"objective\": \"reg:linear\",\n",
    "              \"booster\": \"gbtree\",\n",
    "              \"eta\": eta,\n",
    "              \"max_depth\": depth,\n",
    "              \"min_child_weight\": mcw,\n",
    "              \"subsample\": 0.7,\n",
    "              \"colsample_bytree\": 0.7,\n",
    "              \"silent\": 1\n",
    "              }\n",
    "    print \"Running with params: \" + str(params)\n",
    "    print \"Running with ntrees: \" + str(ntrees)\n",
    "    print \"Running with features: \" + str(features)\n",
    "\n",
    "    # Train model with local split\n",
    "    tsize = 0.05\n",
    "    X_train, X_test = cross_validation.train_test_split(train, test_size=tsize)\n",
    "    dtrain = xgb.DMatrix(X_train[features], np.log(X_train[goal] + 1))\n",
    "    dvalid = xgb.DMatrix(X_test[features], np.log(X_test[goal] + 1))\n",
    "    watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    gbm = xgb.train(params, dtrain, ntrees, evals=watchlist, early_stopping_rounds=100, feval=rmspe_xg, verbose_eval=True)\n",
    "    train_probs = gbm.predict(xgb.DMatrix(X_test[features]))\n",
    "    indices = train_probs < 0\n",
    "    train_probs[indices] = 0\n",
    "    error = rmspe(np.exp(train_probs) - 1, X_test[goal].values)\n",
    "    print error\n",
    "\n",
    "    # Predict and Export\n",
    "    test_probs = gbm.predict(xgb.DMatrix(test[features]))\n",
    "    indices = test_probs < 0\n",
    "    test_probs[indices] = 0\n",
    "    submission = pd.DataFrame({myid: test[myid], goal: np.exp(test_probs) - 1})\n",
    "    if not os.path.exists('result/'):\n",
    "        os.makedirs('result/')\n",
    "    submission.to_csv(\"./result/dat-xgb_d%s_eta%s_ntree%s_mcw%s_tsize%s.csv\" % (str(depth),str(eta),str(ntrees),str(mcw),str(tsize)) , index=False)\n",
    "    # Feature importance\n",
    "    if plot:\n",
    "      outfile = open('xgb.fmap', 'w')\n",
    "      i = 0\n",
    "      for feat in features:\n",
    "          outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "          i = i + 1\n",
    "      outfile.close()\n",
    "      importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "      importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "      df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "      df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "      # Plotitup\n",
    "      plt.figure()\n",
    "      df.plot()\n",
    "      df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(25, 15))\n",
    "      plt.title('XGBoost Feature Importance')\n",
    "      plt.xlabel('relative importance')\n",
    "      plt.gcf().savefig('Feature_Importance_xgb_d%s_eta%s_ntree%s_mcw%s_tsize%s.png' % (str(depth),str(eta),str(ntrees),str(mcw),str(tsize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 载入数据中...\n",
      "=> 处理数据与特征工程...\n",
      "=> 使用XGBoost建模...\n",
      "Running with params: {'subsample': 0.7, 'eta': 0.01, 'colsample_bytree': 0.7, 'silent': 1, 'objective': 'reg:linear', 'max_depth': 6, 'min_child_weight': 3, 'booster': 'gbtree'}\n",
      "Running with ntrees: 8000\n",
      "Running with features: ['Store', 'DayOfWeek', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval', 'year', 'month', 'day']\n",
      "[0]\teval-rmspe:0.999864\ttrain-rmspe:0.999864\n",
      "Multiple eval metrics have been passed: 'train-rmspe' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmspe hasn't improved in 100 rounds.\n",
      "[1]\teval-rmspe:0.999837\ttrain-rmspe:0.999837\n",
      "[2]\teval-rmspe:0.999809\ttrain-rmspe:0.999809\n",
      "[3]\teval-rmspe:0.999779\ttrain-rmspe:0.999779\n",
      "[4]\teval-rmspe:0.999747\ttrain-rmspe:0.999747\n",
      "[5]\teval-rmspe:0.999712\ttrain-rmspe:0.999712\n",
      "[6]\teval-rmspe:0.999675\ttrain-rmspe:0.999675\n",
      "[7]\teval-rmspe:0.999636\ttrain-rmspe:0.999636\n",
      "[8]\teval-rmspe:0.999593\ttrain-rmspe:0.999594\n",
      "[9]\teval-rmspe:0.999548\ttrain-rmspe:0.999548\n",
      "[10]\teval-rmspe:0.9995\ttrain-rmspe:0.9995\n",
      "[11]\teval-rmspe:0.999449\ttrain-rmspe:0.999449\n",
      "[12]\teval-rmspe:0.999394\ttrain-rmspe:0.999394\n",
      "[13]\teval-rmspe:0.999336\ttrain-rmspe:0.999336\n",
      "[14]\teval-rmspe:0.999274\ttrain-rmspe:0.999274\n",
      "[15]\teval-rmspe:0.999208\ttrain-rmspe:0.999209\n",
      "[16]\teval-rmspe:0.999139\ttrain-rmspe:0.999139\n",
      "[17]\teval-rmspe:0.999064\ttrain-rmspe:0.999065\n",
      "[18]\teval-rmspe:0.998986\ttrain-rmspe:0.998986\n",
      "[19]\teval-rmspe:0.998903\ttrain-rmspe:0.998903\n",
      "[20]\teval-rmspe:0.998814\ttrain-rmspe:0.998815\n",
      "[21]\teval-rmspe:0.998721\ttrain-rmspe:0.998721\n",
      "[22]\teval-rmspe:0.998622\ttrain-rmspe:0.998623\n",
      "[23]\teval-rmspe:0.998518\ttrain-rmspe:0.998518\n",
      "[24]\teval-rmspe:0.998407\ttrain-rmspe:0.998408\n",
      "[25]\teval-rmspe:0.998291\ttrain-rmspe:0.998291\n",
      "[26]\teval-rmspe:0.998168\ttrain-rmspe:0.998168\n",
      "[27]\teval-rmspe:0.998038\ttrain-rmspe:0.998039\n",
      "[28]\teval-rmspe:0.997902\ttrain-rmspe:0.997903\n",
      "[29]\teval-rmspe:0.997758\ttrain-rmspe:0.997759\n",
      "[30]\teval-rmspe:0.997607\ttrain-rmspe:0.997607\n",
      "[31]\teval-rmspe:0.997447\ttrain-rmspe:0.997448\n",
      "[32]\teval-rmspe:0.99728\ttrain-rmspe:0.997281\n",
      "[33]\teval-rmspe:0.997104\ttrain-rmspe:0.997105\n",
      "[34]\teval-rmspe:0.99692\ttrain-rmspe:0.996921\n",
      "[35]\teval-rmspe:0.996727\ttrain-rmspe:0.996728\n",
      "[36]\teval-rmspe:0.996524\ttrain-rmspe:0.996525\n",
      "[37]\teval-rmspe:0.996311\ttrain-rmspe:0.996313\n",
      "[38]\teval-rmspe:0.996089\ttrain-rmspe:0.99609\n",
      "[39]\teval-rmspe:0.995856\ttrain-rmspe:0.995857\n",
      "[40]\teval-rmspe:0.995613\ttrain-rmspe:0.995614\n",
      "[41]\teval-rmspe:0.995357\ttrain-rmspe:0.995359\n",
      "[42]\teval-rmspe:0.995091\ttrain-rmspe:0.995092\n",
      "[43]\teval-rmspe:0.994813\ttrain-rmspe:0.994814\n",
      "[44]\teval-rmspe:0.994522\ttrain-rmspe:0.994524\n",
      "[45]\teval-rmspe:0.994219\ttrain-rmspe:0.994221\n",
      "[46]\teval-rmspe:0.993904\ttrain-rmspe:0.993905\n",
      "[47]\teval-rmspe:0.993574\ttrain-rmspe:0.993576\n",
      "[48]\teval-rmspe:0.993232\ttrain-rmspe:0.993234\n",
      "[49]\teval-rmspe:0.992874\ttrain-rmspe:0.992877\n",
      "[50]\teval-rmspe:0.992503\ttrain-rmspe:0.992505\n",
      "[51]\teval-rmspe:0.992117\ttrain-rmspe:0.992119\n",
      "[52]\teval-rmspe:0.991715\ttrain-rmspe:0.991718\n",
      "[53]\teval-rmspe:0.991298\ttrain-rmspe:0.991301\n",
      "[54]\teval-rmspe:0.990864\ttrain-rmspe:0.990868\n",
      "[55]\teval-rmspe:0.990415\ttrain-rmspe:0.990418\n",
      "[56]\teval-rmspe:0.989947\ttrain-rmspe:0.98995\n",
      "[57]\teval-rmspe:0.989463\ttrain-rmspe:0.989466\n",
      "[58]\teval-rmspe:0.988961\ttrain-rmspe:0.988964\n",
      "[59]\teval-rmspe:0.988441\ttrain-rmspe:0.988445\n",
      "[60]\teval-rmspe:0.987902\ttrain-rmspe:0.987906\n",
      "[61]\teval-rmspe:0.987344\ttrain-rmspe:0.987348\n",
      "[62]\teval-rmspe:0.986766\ttrain-rmspe:0.98677\n",
      "[63]\teval-rmspe:0.986168\ttrain-rmspe:0.986173\n",
      "[64]\teval-rmspe:0.985551\ttrain-rmspe:0.985556\n",
      "[65]\teval-rmspe:0.984913\ttrain-rmspe:0.984918\n",
      "[66]\teval-rmspe:0.984254\ttrain-rmspe:0.984259\n",
      "[67]\teval-rmspe:0.983574\ttrain-rmspe:0.98358\n",
      "[68]\teval-rmspe:0.982872\ttrain-rmspe:0.982877\n",
      "[69]\teval-rmspe:0.982148\ttrain-rmspe:0.982154\n",
      "[70]\teval-rmspe:0.981401\ttrain-rmspe:0.981408\n",
      "[71]\teval-rmspe:0.980632\ttrain-rmspe:0.980639\n",
      "[72]\teval-rmspe:0.979838\ttrain-rmspe:0.979845\n",
      "[73]\teval-rmspe:0.979021\ttrain-rmspe:0.979028\n",
      "[74]\teval-rmspe:0.97818\ttrain-rmspe:0.978188\n",
      "[75]\teval-rmspe:0.977312\ttrain-rmspe:0.977321\n",
      "[76]\teval-rmspe:0.976422\ttrain-rmspe:0.976431\n",
      "[77]\teval-rmspe:0.975507\ttrain-rmspe:0.975517\n",
      "[78]\teval-rmspe:0.974567\ttrain-rmspe:0.974577\n",
      "[79]\teval-rmspe:0.973599\ttrain-rmspe:0.97361\n",
      "[80]\teval-rmspe:0.972606\ttrain-rmspe:0.972618\n",
      "[81]\teval-rmspe:0.971586\ttrain-rmspe:0.9716\n",
      "[82]\teval-rmspe:0.970541\ttrain-rmspe:0.970555\n",
      "[83]\teval-rmspe:0.969466\ttrain-rmspe:0.969481\n",
      "[84]\teval-rmspe:0.968365\ttrain-rmspe:0.968381\n",
      "[85]\teval-rmspe:0.967236\ttrain-rmspe:0.967253\n",
      "[86]\teval-rmspe:0.966078\ttrain-rmspe:0.966096\n",
      "[87]\teval-rmspe:0.964894\ttrain-rmspe:0.964912\n",
      "[88]\teval-rmspe:0.96368\ttrain-rmspe:0.963699\n",
      "[89]\teval-rmspe:0.962438\ttrain-rmspe:0.962458\n",
      "[90]\teval-rmspe:0.961163\ttrain-rmspe:0.961185\n",
      "[91]\teval-rmspe:0.959861\ttrain-rmspe:0.959885\n",
      "[92]\teval-rmspe:0.95853\ttrain-rmspe:0.958555\n",
      "[93]\teval-rmspe:0.957168\ttrain-rmspe:0.957195\n",
      "[94]\teval-rmspe:0.955778\ttrain-rmspe:0.955806\n",
      "[95]\teval-rmspe:0.954356\ttrain-rmspe:0.954386\n",
      "[96]\teval-rmspe:0.952903\ttrain-rmspe:0.952934\n",
      "[97]\teval-rmspe:0.951421\ttrain-rmspe:0.951454\n",
      "[98]\teval-rmspe:0.949908\ttrain-rmspe:0.949943\n",
      "[99]\teval-rmspe:0.948362\ttrain-rmspe:0.948399\n",
      "[100]\teval-rmspe:0.946787\ttrain-rmspe:0.946827\n",
      "[101]\teval-rmspe:0.94518\ttrain-rmspe:0.945222\n",
      "[102]\teval-rmspe:0.943543\ttrain-rmspe:0.943588\n",
      "[103]\teval-rmspe:0.941874\ttrain-rmspe:0.941921\n",
      "[104]\teval-rmspe:0.940173\ttrain-rmspe:0.940223\n",
      "[105]\teval-rmspe:0.938439\ttrain-rmspe:0.938491\n",
      "[106]\teval-rmspe:0.936674\ttrain-rmspe:0.936728\n",
      "[107]\teval-rmspe:0.934876\ttrain-rmspe:0.934933\n",
      "[108]\teval-rmspe:0.933048\ttrain-rmspe:0.933109\n",
      "[109]\teval-rmspe:0.93119\ttrain-rmspe:0.931253\n",
      "[110]\teval-rmspe:0.929294\ttrain-rmspe:0.929362\n",
      "[111]\teval-rmspe:0.92737\ttrain-rmspe:0.927441\n",
      "[112]\teval-rmspe:0.925415\ttrain-rmspe:0.925489\n",
      "[113]\teval-rmspe:0.923425\ttrain-rmspe:0.923503\n",
      "[114]\teval-rmspe:0.921401\ttrain-rmspe:0.921484\n",
      "[115]\teval-rmspe:0.919351\ttrain-rmspe:0.919438\n",
      "[116]\teval-rmspe:0.917266\ttrain-rmspe:0.917358\n",
      "[117]\teval-rmspe:0.915152\ttrain-rmspe:0.915249\n",
      "[118]\teval-rmspe:0.913007\ttrain-rmspe:0.913108\n",
      "[119]\teval-rmspe:0.91083\ttrain-rmspe:0.910937\n",
      "[120]\teval-rmspe:0.908622\ttrain-rmspe:0.908733\n",
      "[121]\teval-rmspe:0.906384\ttrain-rmspe:0.906502\n",
      "[122]\teval-rmspe:0.904114\ttrain-rmspe:0.904239\n",
      "[123]\teval-rmspe:0.901814\ttrain-rmspe:0.901945\n",
      "[124]\teval-rmspe:0.899483\ttrain-rmspe:0.89962\n",
      "[125]\teval-rmspe:0.89712\ttrain-rmspe:0.897265\n",
      "[126]\teval-rmspe:0.894726\ttrain-rmspe:0.894879\n",
      "[127]\teval-rmspe:0.892301\ttrain-rmspe:0.892462\n",
      "[128]\teval-rmspe:0.889846\ttrain-rmspe:0.890015\n",
      "[129]\teval-rmspe:0.887363\ttrain-rmspe:0.88754\n",
      "[130]\teval-rmspe:0.88485\ttrain-rmspe:0.885033\n",
      "[131]\teval-rmspe:0.882309\ttrain-rmspe:0.8825\n",
      "[132]\teval-rmspe:0.879736\ttrain-rmspe:0.879935\n",
      "[133]\teval-rmspe:0.877136\ttrain-rmspe:0.877344\n",
      "[134]\teval-rmspe:0.874507\ttrain-rmspe:0.874724\n",
      "[135]\teval-rmspe:0.871851\ttrain-rmspe:0.87208\n",
      "[136]\teval-rmspe:0.869164\ttrain-rmspe:0.869403\n",
      "[137]\teval-rmspe:0.866449\ttrain-rmspe:0.866699\n",
      "[138]\teval-rmspe:0.863707\ttrain-rmspe:0.863969\n",
      "[139]\teval-rmspe:0.860939\ttrain-rmspe:0.861211\n",
      "[140]\teval-rmspe:0.858143\ttrain-rmspe:0.858426\n",
      "[141]\teval-rmspe:0.855321\ttrain-rmspe:0.855615\n",
      "[142]\teval-rmspe:0.852475\ttrain-rmspe:0.852778\n",
      "[143]\teval-rmspe:0.849602\ttrain-rmspe:0.849916\n",
      "[144]\teval-rmspe:0.846705\ttrain-rmspe:0.847032\n",
      "[145]\teval-rmspe:0.843784\ttrain-rmspe:0.844125\n",
      "[146]\teval-rmspe:0.840835\ttrain-rmspe:0.84119\n",
      "[147]\teval-rmspe:0.837865\ttrain-rmspe:0.838236\n",
      "[148]\teval-rmspe:0.83487\ttrain-rmspe:0.835254\n",
      "[149]\teval-rmspe:0.831854\ttrain-rmspe:0.832254\n",
      "[150]\teval-rmspe:0.828813\ttrain-rmspe:0.82923\n",
      "[151]\teval-rmspe:0.82575\ttrain-rmspe:0.826184\n",
      "[152]\teval-rmspe:0.822663\ttrain-rmspe:0.823115\n",
      "[153]\teval-rmspe:0.819556\ttrain-rmspe:0.820026\n",
      "[154]\teval-rmspe:0.816425\ttrain-rmspe:0.816914\n",
      "[155]\teval-rmspe:0.813274\ttrain-rmspe:0.813782\n",
      "[156]\teval-rmspe:0.8101\ttrain-rmspe:0.810629\n",
      "[157]\teval-rmspe:0.806913\ttrain-rmspe:0.807462\n",
      "[158]\teval-rmspe:0.803704\ttrain-rmspe:0.804274\n",
      "[159]\teval-rmspe:0.800476\ttrain-rmspe:0.801067\n",
      "[160]\teval-rmspe:0.797229\ttrain-rmspe:0.797842\n",
      "[161]\teval-rmspe:0.793965\ttrain-rmspe:0.7946\n",
      "[162]\teval-rmspe:0.790682\ttrain-rmspe:0.791342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163]\teval-rmspe:0.787383\ttrain-rmspe:0.788067\n",
      "[164]\teval-rmspe:0.78407\ttrain-rmspe:0.78478\n",
      "[165]\teval-rmspe:0.780734\ttrain-rmspe:0.781471\n",
      "[166]\teval-rmspe:0.777387\ttrain-rmspe:0.778148\n",
      "[167]\teval-rmspe:0.774025\ttrain-rmspe:0.774813\n",
      "[168]\teval-rmspe:0.770645\ttrain-rmspe:0.771461\n",
      "[169]\teval-rmspe:0.767256\ttrain-rmspe:0.768098\n",
      "[170]\teval-rmspe:0.763854\ttrain-rmspe:0.764724\n",
      "[171]\teval-rmspe:0.760434\ttrain-rmspe:0.761332\n",
      "[172]\teval-rmspe:0.757007\ttrain-rmspe:0.757935\n",
      "[173]\teval-rmspe:0.753567\ttrain-rmspe:0.754524\n",
      "[174]\teval-rmspe:0.750122\ttrain-rmspe:0.751114\n",
      "[175]\teval-rmspe:0.746661\ttrain-rmspe:0.747686\n",
      "[176]\teval-rmspe:0.743189\ttrain-rmspe:0.744249\n",
      "[177]\teval-rmspe:0.739706\ttrain-rmspe:0.740801\n",
      "[178]\teval-rmspe:0.736213\ttrain-rmspe:0.737342\n",
      "[179]\teval-rmspe:0.732709\ttrain-rmspe:0.733874\n",
      "[180]\teval-rmspe:0.729199\ttrain-rmspe:0.730398\n",
      "[181]\teval-rmspe:0.725683\ttrain-rmspe:0.726921\n",
      "[182]\teval-rmspe:0.72216\ttrain-rmspe:0.723437\n",
      "[183]\teval-rmspe:0.718632\ttrain-rmspe:0.71995\n",
      "[184]\teval-rmspe:0.715097\ttrain-rmspe:0.716458\n",
      "[185]\teval-rmspe:0.711561\ttrain-rmspe:0.712959\n",
      "[186]\teval-rmspe:0.708017\ttrain-rmspe:0.709458\n",
      "[187]\teval-rmspe:0.704468\ttrain-rmspe:0.705953\n",
      "[188]\teval-rmspe:0.700917\ttrain-rmspe:0.702444\n",
      "[189]\teval-rmspe:0.69736\ttrain-rmspe:0.698934\n",
      "[190]\teval-rmspe:0.693796\ttrain-rmspe:0.695415\n",
      "[191]\teval-rmspe:0.690233\ttrain-rmspe:0.691899\n",
      "[192]\teval-rmspe:0.686672\ttrain-rmspe:0.688381\n",
      "[193]\teval-rmspe:0.683107\ttrain-rmspe:0.684866\n",
      "[194]\teval-rmspe:0.679546\ttrain-rmspe:0.68135\n",
      "[195]\teval-rmspe:0.675981\ttrain-rmspe:0.677836\n",
      "[196]\teval-rmspe:0.672415\ttrain-rmspe:0.674323\n",
      "[197]\teval-rmspe:0.668855\ttrain-rmspe:0.670817\n",
      "[198]\teval-rmspe:0.665291\ttrain-rmspe:0.667309\n",
      "[199]\teval-rmspe:0.661728\ttrain-rmspe:0.663806\n",
      "[200]\teval-rmspe:0.658167\ttrain-rmspe:0.660294\n",
      "[201]\teval-rmspe:0.654608\ttrain-rmspe:0.656795\n",
      "[202]\teval-rmspe:0.651053\ttrain-rmspe:0.653302\n",
      "[203]\teval-rmspe:0.6475\ttrain-rmspe:0.649812\n",
      "[204]\teval-rmspe:0.643953\ttrain-rmspe:0.646327\n",
      "[205]\teval-rmspe:0.64041\ttrain-rmspe:0.642846\n",
      "[206]\teval-rmspe:0.636872\ttrain-rmspe:0.639375\n",
      "[207]\teval-rmspe:0.63334\ttrain-rmspe:0.63591\n",
      "[208]\teval-rmspe:0.629817\ttrain-rmspe:0.632452\n",
      "[209]\teval-rmspe:0.6263\ttrain-rmspe:0.629003\n",
      "[210]\teval-rmspe:0.622785\ttrain-rmspe:0.625559\n",
      "[211]\teval-rmspe:0.619282\ttrain-rmspe:0.622128\n",
      "[212]\teval-rmspe:0.615785\ttrain-rmspe:0.618706\n",
      "[213]\teval-rmspe:0.612298\ttrain-rmspe:0.615294\n",
      "[214]\teval-rmspe:0.608822\ttrain-rmspe:0.611894\n",
      "[215]\teval-rmspe:0.605361\ttrain-rmspe:0.608504\n",
      "[216]\teval-rmspe:0.601899\ttrain-rmspe:0.605119\n",
      "[217]\teval-rmspe:0.598451\ttrain-rmspe:0.601749\n",
      "[218]\teval-rmspe:0.595012\ttrain-rmspe:0.598391\n",
      "[219]\teval-rmspe:0.591592\ttrain-rmspe:0.595048\n",
      "[220]\teval-rmspe:0.588177\ttrain-rmspe:0.591717\n",
      "[221]\teval-rmspe:0.584775\ttrain-rmspe:0.588397\n",
      "[222]\teval-rmspe:0.581385\ttrain-rmspe:0.585093\n",
      "[223]\teval-rmspe:0.578008\ttrain-rmspe:0.581804\n",
      "[224]\teval-rmspe:0.574642\ttrain-rmspe:0.578528\n",
      "[225]\teval-rmspe:0.571289\ttrain-rmspe:0.575266\n",
      "[226]\teval-rmspe:0.567952\ttrain-rmspe:0.572021\n",
      "[227]\teval-rmspe:0.56463\ttrain-rmspe:0.568789\n",
      "[228]\teval-rmspe:0.561322\ttrain-rmspe:0.565576\n",
      "[229]\teval-rmspe:0.55803\ttrain-rmspe:0.562382\n",
      "[230]\teval-rmspe:0.554753\ttrain-rmspe:0.559202\n",
      "[231]\teval-rmspe:0.551494\ttrain-rmspe:0.556044\n",
      "[232]\teval-rmspe:0.548251\ttrain-rmspe:0.552899\n",
      "[233]\teval-rmspe:0.545021\ttrain-rmspe:0.549766\n",
      "[234]\teval-rmspe:0.541808\ttrain-rmspe:0.546656\n",
      "[235]\teval-rmspe:0.538617\ttrain-rmspe:0.543563\n",
      "[236]\teval-rmspe:0.535442\ttrain-rmspe:0.540492\n",
      "[237]\teval-rmspe:0.53228\ttrain-rmspe:0.53744\n",
      "[238]\teval-rmspe:0.529134\ttrain-rmspe:0.534403\n",
      "[239]\teval-rmspe:0.526008\ttrain-rmspe:0.531375\n",
      "[240]\teval-rmspe:0.522907\ttrain-rmspe:0.528395\n",
      "[241]\teval-rmspe:0.519819\ttrain-rmspe:0.525418\n",
      "[242]\teval-rmspe:0.516756\ttrain-rmspe:0.522468\n",
      "[243]\teval-rmspe:0.513708\ttrain-rmspe:0.519536\n",
      "[244]\teval-rmspe:0.510685\ttrain-rmspe:0.516629\n",
      "[245]\teval-rmspe:0.507683\ttrain-rmspe:0.513746\n",
      "[246]\teval-rmspe:0.504689\ttrain-rmspe:0.510873\n",
      "[247]\teval-rmspe:0.501725\ttrain-rmspe:0.508029\n",
      "[248]\teval-rmspe:0.498785\ttrain-rmspe:0.505211\n",
      "[249]\teval-rmspe:0.495863\ttrain-rmspe:0.502416\n",
      "[250]\teval-rmspe:0.492956\ttrain-rmspe:0.49964\n",
      "[251]\teval-rmspe:0.49008\ttrain-rmspe:0.496898\n",
      "[252]\teval-rmspe:0.487212\ttrain-rmspe:0.49416\n",
      "[253]\teval-rmspe:0.484381\ttrain-rmspe:0.491459\n",
      "[254]\teval-rmspe:0.481568\ttrain-rmspe:0.488777\n",
      "[255]\teval-rmspe:0.478777\ttrain-rmspe:0.486122\n",
      "[256]\teval-rmspe:0.476009\ttrain-rmspe:0.483487\n",
      "[257]\teval-rmspe:0.473268\ttrain-rmspe:0.480884\n",
      "[258]\teval-rmspe:0.470537\ttrain-rmspe:0.478294\n",
      "[259]\teval-rmspe:0.467833\ttrain-rmspe:0.475718\n",
      "[260]\teval-rmspe:0.465162\ttrain-rmspe:0.473188\n",
      "[261]\teval-rmspe:0.462496\ttrain-rmspe:0.470658\n",
      "[262]\teval-rmspe:0.459871\ttrain-rmspe:0.468175\n",
      "[263]\teval-rmspe:0.457265\ttrain-rmspe:0.46571\n",
      "[264]\teval-rmspe:0.454691\ttrain-rmspe:0.463289\n",
      "[265]\teval-rmspe:0.452142\ttrain-rmspe:0.460885\n",
      "[266]\teval-rmspe:0.449598\ttrain-rmspe:0.458478\n",
      "[267]\teval-rmspe:0.447092\ttrain-rmspe:0.45612\n",
      "[268]\teval-rmspe:0.444557\ttrain-rmspe:0.453746\n",
      "[269]\teval-rmspe:0.442097\ttrain-rmspe:0.451428\n",
      "[270]\teval-rmspe:0.439657\ttrain-rmspe:0.449145\n",
      "[271]\teval-rmspe:0.437252\ttrain-rmspe:0.446888\n",
      "[272]\teval-rmspe:0.434866\ttrain-rmspe:0.444657\n",
      "[273]\teval-rmspe:0.432503\ttrain-rmspe:0.442449\n",
      "[274]\teval-rmspe:0.430178\ttrain-rmspe:0.440283\n",
      "[275]\teval-rmspe:0.427876\ttrain-rmspe:0.438143\n",
      "[276]\teval-rmspe:0.425588\ttrain-rmspe:0.436012\n",
      "[277]\teval-rmspe:0.423333\ttrain-rmspe:0.433926\n",
      "[278]\teval-rmspe:0.421106\ttrain-rmspe:0.431859\n",
      "[279]\teval-rmspe:0.418878\ttrain-rmspe:0.429759\n",
      "[280]\teval-rmspe:0.416704\ttrain-rmspe:0.427743\n",
      "[281]\teval-rmspe:0.414556\ttrain-rmspe:0.425757\n",
      "[282]\teval-rmspe:0.412434\ttrain-rmspe:0.423801\n",
      "[283]\teval-rmspe:0.410349\ttrain-rmspe:0.421879\n",
      "[284]\teval-rmspe:0.408254\ttrain-rmspe:0.419953\n",
      "[285]\teval-rmspe:0.406211\ttrain-rmspe:0.418074\n",
      "[286]\teval-rmspe:0.404195\ttrain-rmspe:0.416225\n",
      "[287]\teval-rmspe:0.402202\ttrain-rmspe:0.414397\n",
      "[288]\teval-rmspe:0.400244\ttrain-rmspe:0.412607\n",
      "[289]\teval-rmspe:0.398297\ttrain-rmspe:0.410834\n",
      "[290]\teval-rmspe:0.396387\ttrain-rmspe:0.409075\n",
      "[291]\teval-rmspe:0.394483\ttrain-rmspe:0.407341\n",
      "[292]\teval-rmspe:0.392617\ttrain-rmspe:0.405652\n",
      "[293]\teval-rmspe:0.390774\ttrain-rmspe:0.403982\n",
      "[294]\teval-rmspe:0.388964\ttrain-rmspe:0.402323\n",
      "[295]\teval-rmspe:0.38718\ttrain-rmspe:0.400697\n",
      "[296]\teval-rmspe:0.385399\ttrain-rmspe:0.399075\n",
      "[297]\teval-rmspe:0.383675\ttrain-rmspe:0.397527\n",
      "[298]\teval-rmspe:0.381953\ttrain-rmspe:0.395985\n",
      "[299]\teval-rmspe:0.380239\ttrain-rmspe:0.394449\n",
      "[300]\teval-rmspe:0.378577\ttrain-rmspe:0.392965\n",
      "[301]\teval-rmspe:0.376918\ttrain-rmspe:0.39147\n",
      "[302]\teval-rmspe:0.375298\ttrain-rmspe:0.390026\n",
      "[303]\teval-rmspe:0.373688\ttrain-rmspe:0.388572\n",
      "[304]\teval-rmspe:0.372114\ttrain-rmspe:0.387171\n",
      "[305]\teval-rmspe:0.37058\ttrain-rmspe:0.385771\n",
      "[306]\teval-rmspe:0.369081\ttrain-rmspe:0.384444\n",
      "[307]\teval-rmspe:0.367601\ttrain-rmspe:0.383137\n",
      "[308]\teval-rmspe:0.366143\ttrain-rmspe:0.381845\n",
      "[309]\teval-rmspe:0.364677\ttrain-rmspe:0.380534\n",
      "[310]\teval-rmspe:0.363261\ttrain-rmspe:0.379292\n",
      "[311]\teval-rmspe:0.361841\ttrain-rmspe:0.378049\n",
      "[312]\teval-rmspe:0.360473\ttrain-rmspe:0.376854\n",
      "[313]\teval-rmspe:0.359112\ttrain-rmspe:0.375653\n",
      "[314]\teval-rmspe:0.357776\ttrain-rmspe:0.374473\n",
      "[315]\teval-rmspe:0.356464\ttrain-rmspe:0.373346\n",
      "[316]\teval-rmspe:0.355192\ttrain-rmspe:0.372247\n",
      "[317]\teval-rmspe:0.35391\ttrain-rmspe:0.371121\n",
      "[318]\teval-rmspe:0.352651\ttrain-rmspe:0.37003\n",
      "[319]\teval-rmspe:0.351456\ttrain-rmspe:0.368999\n",
      "[320]\teval-rmspe:0.35025\ttrain-rmspe:0.367958\n",
      "[321]\teval-rmspe:0.349087\ttrain-rmspe:0.366972\n",
      "[322]\teval-rmspe:0.347947\ttrain-rmspe:0.366002\n",
      "[323]\teval-rmspe:0.346812\ttrain-rmspe:0.365037\n",
      "[324]\teval-rmspe:0.345707\ttrain-rmspe:0.3641\n",
      "[325]\teval-rmspe:0.344648\ttrain-rmspe:0.363202\n",
      "[326]\teval-rmspe:0.343574\ttrain-rmspe:0.362282\n",
      "[327]\teval-rmspe:0.342518\ttrain-rmspe:0.361375\n",
      "[328]\teval-rmspe:0.341515\ttrain-rmspe:0.360544\n",
      "[329]\teval-rmspe:0.340527\ttrain-rmspe:0.359716\n",
      "[330]\teval-rmspe:0.339528\ttrain-rmspe:0.358892\n",
      "[331]\teval-rmspe:0.338545\ttrain-rmspe:0.35806\n",
      "[332]\teval-rmspe:0.337578\ttrain-rmspe:0.357254\n",
      "[333]\teval-rmspe:0.336688\ttrain-rmspe:0.356516\n",
      "[334]\teval-rmspe:0.335812\ttrain-rmspe:0.355802\n",
      "[335]\teval-rmspe:0.334891\ttrain-rmspe:0.355038\n",
      "[336]\teval-rmspe:0.334061\ttrain-rmspe:0.354365\n",
      "[337]\teval-rmspe:0.333205\ttrain-rmspe:0.353658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[338]\teval-rmspe:0.332402\ttrain-rmspe:0.353013\n",
      "[339]\teval-rmspe:0.331578\ttrain-rmspe:0.352347\n",
      "[340]\teval-rmspe:0.330817\ttrain-rmspe:0.351739\n",
      "[341]\teval-rmspe:0.33008\ttrain-rmspe:0.351152\n",
      "[342]\teval-rmspe:0.329353\ttrain-rmspe:0.350578\n",
      "[343]\teval-rmspe:0.328602\ttrain-rmspe:0.349975\n",
      "[344]\teval-rmspe:0.327925\ttrain-rmspe:0.349443\n",
      "[345]\teval-rmspe:0.327249\ttrain-rmspe:0.348919\n",
      "[346]\teval-rmspe:0.326556\ttrain-rmspe:0.348387\n",
      "[347]\teval-rmspe:0.325929\ttrain-rmspe:0.347908\n",
      "[348]\teval-rmspe:0.325285\ttrain-rmspe:0.347414\n",
      "[349]\teval-rmspe:0.324683\ttrain-rmspe:0.346908\n",
      "[350]\teval-rmspe:0.324065\ttrain-rmspe:0.346413\n",
      "[351]\teval-rmspe:0.323469\ttrain-rmspe:0.345963\n",
      "[352]\teval-rmspe:0.322896\ttrain-rmspe:0.345502\n",
      "[353]\teval-rmspe:0.322312\ttrain-rmspe:0.34506\n",
      "[354]\teval-rmspe:0.321755\ttrain-rmspe:0.344653\n",
      "[355]\teval-rmspe:0.321215\ttrain-rmspe:0.344246\n",
      "[356]\teval-rmspe:0.32073\ttrain-rmspe:0.343898\n",
      "[357]\teval-rmspe:0.320203\ttrain-rmspe:0.343501\n",
      "[358]\teval-rmspe:0.31974\ttrain-rmspe:0.343173\n",
      "[359]\teval-rmspe:0.319242\ttrain-rmspe:0.342809\n",
      "[360]\teval-rmspe:0.318789\ttrain-rmspe:0.34249\n",
      "[361]\teval-rmspe:0.318352\ttrain-rmspe:0.342185\n",
      "[362]\teval-rmspe:0.31791\ttrain-rmspe:0.341877\n",
      "[363]\teval-rmspe:0.317478\ttrain-rmspe:0.341549\n",
      "[364]\teval-rmspe:0.31705\ttrain-rmspe:0.341257\n",
      "[365]\teval-rmspe:0.316637\ttrain-rmspe:0.340958\n",
      "[366]\teval-rmspe:0.316203\ttrain-rmspe:0.340626\n",
      "[367]\teval-rmspe:0.315802\ttrain-rmspe:0.340325\n",
      "[368]\teval-rmspe:0.315452\ttrain-rmspe:0.340088\n",
      "[369]\teval-rmspe:0.315133\ttrain-rmspe:0.339885\n",
      "[370]\teval-rmspe:0.31479\ttrain-rmspe:0.339642\n",
      "[371]\teval-rmspe:0.314407\ttrain-rmspe:0.339326\n",
      "[372]\teval-rmspe:0.314066\ttrain-rmspe:0.339087\n",
      "[373]\teval-rmspe:0.313745\ttrain-rmspe:0.338888\n",
      "[374]\teval-rmspe:0.313429\ttrain-rmspe:0.338693\n",
      "[375]\teval-rmspe:0.313149\ttrain-rmspe:0.338534\n",
      "[376]\teval-rmspe:0.312862\ttrain-rmspe:0.33835\n",
      "[377]\teval-rmspe:0.312623\ttrain-rmspe:0.338217\n",
      "[378]\teval-rmspe:0.312413\ttrain-rmspe:0.338107\n",
      "[379]\teval-rmspe:0.312184\ttrain-rmspe:0.337997\n",
      "[380]\teval-rmspe:0.311989\ttrain-rmspe:0.3379\n",
      "[381]\teval-rmspe:0.311735\ttrain-rmspe:0.337745\n",
      "[382]\teval-rmspe:0.311543\ttrain-rmspe:0.337662\n",
      "[383]\teval-rmspe:0.311355\ttrain-rmspe:0.337576\n",
      "[384]\teval-rmspe:0.311183\ttrain-rmspe:0.337505\n",
      "[385]\teval-rmspe:0.310986\ttrain-rmspe:0.337415\n",
      "[386]\teval-rmspe:0.310798\ttrain-rmspe:0.337305\n",
      "[387]\teval-rmspe:0.310607\ttrain-rmspe:0.33721\n",
      "[388]\teval-rmspe:0.310389\ttrain-rmspe:0.337094\n",
      "[389]\teval-rmspe:0.310228\ttrain-rmspe:0.337031\n",
      "[390]\teval-rmspe:0.310053\ttrain-rmspe:0.336947\n",
      "[391]\teval-rmspe:0.309879\ttrain-rmspe:0.336887\n",
      "[392]\teval-rmspe:0.309725\ttrain-rmspe:0.336831\n",
      "[393]\teval-rmspe:0.309595\ttrain-rmspe:0.336779\n",
      "[394]\teval-rmspe:0.309501\ttrain-rmspe:0.336773\n",
      "[395]\teval-rmspe:0.309397\ttrain-rmspe:0.336757\n",
      "[396]\teval-rmspe:0.309238\ttrain-rmspe:0.336641\n",
      "[397]\teval-rmspe:0.309111\ttrain-rmspe:0.336606\n",
      "[398]\teval-rmspe:0.309061\ttrain-rmspe:0.33664\n",
      "[399]\teval-rmspe:0.308896\ttrain-rmspe:0.33652\n",
      "[400]\teval-rmspe:0.308765\ttrain-rmspe:0.336466\n",
      "[401]\teval-rmspe:0.308645\ttrain-rmspe:0.336445\n",
      "[402]\teval-rmspe:0.30853\ttrain-rmspe:0.336429\n",
      "[403]\teval-rmspe:0.308464\ttrain-rmspe:0.336441\n",
      "[404]\teval-rmspe:0.308364\ttrain-rmspe:0.336416\n",
      "[405]\teval-rmspe:0.308263\ttrain-rmspe:0.336416\n",
      "[406]\teval-rmspe:0.308192\ttrain-rmspe:0.336425\n",
      "[407]\teval-rmspe:0.308079\ttrain-rmspe:0.336384\n",
      "[408]\teval-rmspe:0.308052\ttrain-rmspe:0.336417\n",
      "[409]\teval-rmspe:0.30798\ttrain-rmspe:0.336424\n",
      "[410]\teval-rmspe:0.307974\ttrain-rmspe:0.336487\n",
      "[411]\teval-rmspe:0.30776\ttrain-rmspe:0.336375\n",
      "[412]\teval-rmspe:0.307778\ttrain-rmspe:0.33646\n",
      "[413]\teval-rmspe:0.307781\ttrain-rmspe:0.336528\n",
      "[414]\teval-rmspe:0.307818\ttrain-rmspe:0.33663\n",
      "[415]\teval-rmspe:0.307835\ttrain-rmspe:0.336706\n",
      "[416]\teval-rmspe:0.307799\ttrain-rmspe:0.33675\n",
      "[417]\teval-rmspe:0.307828\ttrain-rmspe:0.336844\n",
      "[418]\teval-rmspe:0.307644\ttrain-rmspe:0.336759\n",
      "[419]\teval-rmspe:0.30762\ttrain-rmspe:0.33678\n",
      "[420]\teval-rmspe:0.307669\ttrain-rmspe:0.336899\n",
      "[421]\teval-rmspe:0.307626\ttrain-rmspe:0.336939\n",
      "[422]\teval-rmspe:0.307652\ttrain-rmspe:0.337029\n",
      "[423]\teval-rmspe:0.307696\ttrain-rmspe:0.337104\n",
      "[424]\teval-rmspe:0.307777\ttrain-rmspe:0.337241\n",
      "[425]\teval-rmspe:0.307738\ttrain-rmspe:0.337264\n",
      "[426]\teval-rmspe:0.307771\ttrain-rmspe:0.337356\n",
      "[427]\teval-rmspe:0.307769\ttrain-rmspe:0.337404\n",
      "[428]\teval-rmspe:0.307805\ttrain-rmspe:0.337495\n",
      "[429]\teval-rmspe:0.30789\ttrain-rmspe:0.337631\n",
      "[430]\teval-rmspe:0.307974\ttrain-rmspe:0.337769\n",
      "[431]\teval-rmspe:0.308022\ttrain-rmspe:0.337871\n",
      "[432]\teval-rmspe:0.308078\ttrain-rmspe:0.337965\n",
      "[433]\teval-rmspe:0.307871\ttrain-rmspe:0.33783\n",
      "[434]\teval-rmspe:0.307739\ttrain-rmspe:0.337773\n",
      "[435]\teval-rmspe:0.307815\ttrain-rmspe:0.3379\n",
      "[436]\teval-rmspe:0.30788\ttrain-rmspe:0.338009\n",
      "[437]\teval-rmspe:0.307968\ttrain-rmspe:0.338151\n",
      "[438]\teval-rmspe:0.30806\ttrain-rmspe:0.338307\n",
      "[439]\teval-rmspe:0.308006\ttrain-rmspe:0.338318\n",
      "[440]\teval-rmspe:0.308031\ttrain-rmspe:0.338413\n",
      "[441]\teval-rmspe:0.308128\ttrain-rmspe:0.338551\n",
      "[442]\teval-rmspe:0.308189\ttrain-rmspe:0.338675\n",
      "[443]\teval-rmspe:0.308298\ttrain-rmspe:0.338825\n",
      "[444]\teval-rmspe:0.308252\ttrain-rmspe:0.338783\n",
      "[445]\teval-rmspe:0.308067\ttrain-rmspe:0.338652\n",
      "[446]\teval-rmspe:0.308166\ttrain-rmspe:0.338794\n",
      "[447]\teval-rmspe:0.308013\ttrain-rmspe:0.338697\n",
      "[448]\teval-rmspe:0.308106\ttrain-rmspe:0.338838\n",
      "[449]\teval-rmspe:0.308108\ttrain-rmspe:0.338886\n",
      "[450]\teval-rmspe:0.308062\ttrain-rmspe:0.338884\n",
      "[451]\teval-rmspe:0.30791\ttrain-rmspe:0.338807\n",
      "[452]\teval-rmspe:0.307909\ttrain-rmspe:0.338879\n",
      "[453]\teval-rmspe:0.308032\ttrain-rmspe:0.339041\n",
      "[454]\teval-rmspe:0.308023\ttrain-rmspe:0.339079\n",
      "[455]\teval-rmspe:0.308116\ttrain-rmspe:0.339224\n",
      "[456]\teval-rmspe:0.308217\ttrain-rmspe:0.339369\n",
      "[457]\teval-rmspe:0.308115\ttrain-rmspe:0.339309\n",
      "[458]\teval-rmspe:0.308221\ttrain-rmspe:0.339458\n",
      "[459]\teval-rmspe:0.308238\ttrain-rmspe:0.339513\n",
      "[460]\teval-rmspe:0.308363\ttrain-rmspe:0.339683\n",
      "[461]\teval-rmspe:0.308407\ttrain-rmspe:0.339771\n",
      "[462]\teval-rmspe:0.308524\ttrain-rmspe:0.339924\n",
      "[463]\teval-rmspe:0.308583\ttrain-rmspe:0.340015\n",
      "[464]\teval-rmspe:0.308465\ttrain-rmspe:0.339952\n",
      "[465]\teval-rmspe:0.308476\ttrain-rmspe:0.340022\n",
      "[466]\teval-rmspe:0.308547\ttrain-rmspe:0.340137\n",
      "[467]\teval-rmspe:0.308644\ttrain-rmspe:0.34027\n",
      "[468]\teval-rmspe:0.308663\ttrain-rmspe:0.340341\n",
      "[469]\teval-rmspe:0.308707\ttrain-rmspe:0.340431\n",
      "[470]\teval-rmspe:0.308747\ttrain-rmspe:0.340518\n",
      "[471]\teval-rmspe:0.308795\ttrain-rmspe:0.340583\n",
      "[472]\teval-rmspe:0.30882\ttrain-rmspe:0.340666\n",
      "[473]\teval-rmspe:0.308906\ttrain-rmspe:0.340786\n",
      "[474]\teval-rmspe:0.308979\ttrain-rmspe:0.340903\n",
      "[475]\teval-rmspe:0.309109\ttrain-rmspe:0.341058\n",
      "[476]\teval-rmspe:0.30921\ttrain-rmspe:0.341184\n",
      "[477]\teval-rmspe:0.309249\ttrain-rmspe:0.341267\n",
      "[478]\teval-rmspe:0.309372\ttrain-rmspe:0.341415\n",
      "[479]\teval-rmspe:0.309409\ttrain-rmspe:0.341497\n",
      "[480]\teval-rmspe:0.309452\ttrain-rmspe:0.341563\n",
      "[481]\teval-rmspe:0.309387\ttrain-rmspe:0.341556\n",
      "[482]\teval-rmspe:0.309437\ttrain-rmspe:0.341635\n",
      "[483]\teval-rmspe:0.309564\ttrain-rmspe:0.341787\n",
      "[484]\teval-rmspe:0.309535\ttrain-rmspe:0.34175\n",
      "[485]\teval-rmspe:0.30956\ttrain-rmspe:0.341791\n",
      "[486]\teval-rmspe:0.309436\ttrain-rmspe:0.341704\n",
      "[487]\teval-rmspe:0.309565\ttrain-rmspe:0.341853\n",
      "[488]\teval-rmspe:0.309517\ttrain-rmspe:0.341837\n",
      "[489]\teval-rmspe:0.30962\ttrain-rmspe:0.34196\n",
      "[490]\teval-rmspe:0.309733\ttrain-rmspe:0.342092\n",
      "[491]\teval-rmspe:0.309745\ttrain-rmspe:0.342169\n",
      "[492]\teval-rmspe:0.309786\ttrain-rmspe:0.342255\n",
      "[493]\teval-rmspe:0.309907\ttrain-rmspe:0.3424\n",
      "[494]\teval-rmspe:0.309755\ttrain-rmspe:0.342282\n",
      "[495]\teval-rmspe:0.309657\ttrain-rmspe:0.34223\n",
      "[496]\teval-rmspe:0.309632\ttrain-rmspe:0.342255\n",
      "[497]\teval-rmspe:0.309579\ttrain-rmspe:0.342234\n",
      "[498]\teval-rmspe:0.309679\ttrain-rmspe:0.342362\n",
      "[499]\teval-rmspe:0.309557\ttrain-rmspe:0.342284\n",
      "[500]\teval-rmspe:0.309579\ttrain-rmspe:0.342311\n",
      "[501]\teval-rmspe:0.309455\ttrain-rmspe:0.342231\n",
      "[502]\teval-rmspe:0.309557\ttrain-rmspe:0.342346\n",
      "[503]\teval-rmspe:0.309527\ttrain-rmspe:0.34236\n",
      "[504]\teval-rmspe:0.309628\ttrain-rmspe:0.342485\n",
      "[505]\teval-rmspe:0.309736\ttrain-rmspe:0.342608\n",
      "[506]\teval-rmspe:0.309819\ttrain-rmspe:0.342697\n",
      "[507]\teval-rmspe:0.309894\ttrain-rmspe:0.342799\n",
      "[508]\teval-rmspe:0.310012\ttrain-rmspe:0.342934\n",
      "[509]\teval-rmspe:0.310025\ttrain-rmspe:0.342957\n",
      "[510]\teval-rmspe:0.310033\ttrain-rmspe:0.342999\n",
      "[511]\teval-rmspe:0.310142\ttrain-rmspe:0.343124\n",
      "Stopping. Best iteration:\n",
      "[411]\teval-rmspe:0.30776\ttrain-rmspe:0.336375\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.310142364437\n"
     ]
    }
   ],
   "source": [
    "print \"=> 载入数据中...\"\n",
    "train,test,features,features_non_numeric = load_data()\n",
    "print \"=> 处理数据与特征工程...\"\n",
    "train,test,features,features_non_numeric = process_data(train,test,features,features_non_numeric)\n",
    "print \"=> 使用XGBoost建模...\"\n",
    "XGB_native(train,test,features,features_non_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
