{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 便利店销量预测\n",
    "这是[便利店销量预测比赛](https://www.kaggle.com/c/rossmann-store-sales)的一个简单尝试参考。<br>\n",
    "by [@寒小阳](http://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"page-name\">\n",
    "    Forecast sales using store, promotion, and competitor data\n",
    "</h1>\n",
    "\n",
    "\n",
    "<p>Rossmann operates over 3,000 drug stores in 7 European countries. Currently, <br />Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.</p>\n",
    "<p><span style=\"font-size: 1em; line-height: 1.5em;\">In their first Kaggle competition, Rossmann is challenging you to predict 6 weeks of daily sales for 1,115 stores located across Germany. Reliable sales forecasts enable store managers to create effective staff schedules that increase productivity and motivation. By helping Rossmann create a robust prediction model, you will help store managers stay focused on what’s most important to them: their customers and their teams! </span></p>\n",
    "<p><span style=\"font-size: 1em; line-height: 1.5em;\"> <img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/4594/media/rossmann_banner2.png\" alt=\"\" height=\"81\" width=\"640\" /><br /></span></p>\n",
    "<p><em><span style=\"font-size: 1em; line-height: 1.5em;\">If you are interested in joining Rossmann at their headquarters near Hanover, Germany, please contact Mr. Frank König (Frank.Koenig {at} rossmann.de) Rossmann is currently recruiting data scientists at <a href=\"http://www.rossmann.de/unternehmen/karriere/stellenboerse/stellenanzeigen~jid=3A5205E3-C4F9-4F5D-AA93-438D0B064D70~\">senior</a> and <a href=\"http://www.rossmann.de/unternehmen/karriere/stellenboerse/stellenanzeigen~jid=F5142F37-C823-4767-B7CF-21DE3B351D66~\">entry-level</a> positions.</span></em></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据\n",
    "<table id=\"data-files\" class=\"nicetable full roomy align-top border\">   \n",
    "<thead>\n",
    "    <tr>\n",
    "        <th colspan=\"2\">File Name</th> \n",
    "        <th>Available Formats</th>         \n",
    "    </tr> \n",
    "</thead>\n",
    "\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">sample_submission.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/sample_submission.csv.zip\" name=\"sample_submission.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (55.25 kb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">store.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/store.csv.zip\" name=\"store.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (8.33 kb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">test.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/test.csv.zip\" name=\"test.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (143.25 kb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "    <tbody  >\n",
    "        <tr>\n",
    "\n",
    "            <td class=\"file-name\" colspan=\"2\" rowspan=\"1\">train.csv</td>\n",
    "            <td>\n",
    "<a href=\"/c/rossmann-store-sales/download/train.csv.zip\" name=\"train.csv.zip\" onclick=\"window.Intercom(&#39;trackEvent&#39;,&#39;download_compdata&#39;,{&#39;comp_id&#39;: 4594});\">.zip (5.66 mb)</a>                    </td>\n",
    "        </tr>\n",
    "\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Files</h3>\n",
    "<ul>\n",
    "<li><strong>train.csv</strong> - historical data including Sales</li>\n",
    "<li><strong>test.csv</strong> - historical data excluding Sales</li>\n",
    "<li><strong>sample_submission.csv</strong> - a sample submission file in the correct format</li>\n",
    "<li><strong>store.csv</strong> - supplemental information about the stores</li>\n",
    "</ul>\n",
    "<h3>Data fields</h3>\n",
    "<p>Most of the fields are self-explanatory. The following are descriptions for those that aren't.</p>\n",
    "<ul>\n",
    "<li><strong>Id</strong> - an Id that represents a (Store, Date) duple within the test set</li>\n",
    "<li><strong>Store</strong> - a unique Id for each store</li>\n",
    "<li><strong>Sales</strong> - the turnover for any given day (this is what you are predicting)</li>\n",
    "<li><strong>Customers</strong> - the number of customers on a given day</li>\n",
    "<li><strong>Open</strong> - an indicator for whether the store was open: 0 = closed, 1 = open</li>\n",
    "<li><strong>StateHoliday</strong> - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None</li>\n",
    "<li><strong>SchoolHoliday</strong> - indicates if the (Store, Date) was affected by the closure of public schools</li>\n",
    "<li><strong>StoreType</strong> - differentiates between 4 different store models: a, b, c, d</li>\n",
    "<li><strong>Assortment</strong> - describes an assortment level: a = basic, b = extra, c = extended</li>\n",
    "<li><strong>CompetitionDistance</strong> - distance in meters to the nearest competitor store</li>\n",
    "<li><strong>CompetitionOpenSince[Month/Year]</strong> - gives the approximate year and month of the time the nearest competitor was opened</li>\n",
    "<li><strong>Promo</strong> - indicates whether a store is running a promo on that day</li>\n",
    "<li><strong>Promo2</strong> - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating</li>\n",
    "<li><strong>Promo2Since[Year/Week]</strong> - describes the year and calendar week when the store started participating in Promo2</li>\n",
    "<li><strong>PromoInterval</strong> - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入所需的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy as sp\n",
    "import xgboost as xgb\n",
    "import itertools\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import cross_validation\n",
    "from matplotlib import pylab as plt\n",
    "plot = True\n",
    "\n",
    "goal = 'Sales'\n",
    "myid = 'Id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当你的eval metric和loss function并不一致的时候\n",
    "\n",
    "### Early stopping\n",
    "按照原来的loss function去优化，一颗一颗树生长和添加，但是在验证集上，盯着eval metric去看，在验证集上评估指标不再优化的时候，停止集成模型的生长。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有标签的数据部分(训练集) + 无标签/需要做预估的部分(测试集)<br>\n",
    "训练集 = 真正的训练集 + 验证集(利用它去完成模型选择和调参)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义一些变换和评判准则\n",
    "使用不同的evaluation function的时候要特别注意这个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ToWeight(y):\n",
    "    # y is np.array\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "def rmspe(yhat, y):\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n",
    "    return rmspe\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    # y = y.values\n",
    "    y = y.get_label()\n",
    "    y = np.exp(y) - 1\n",
    "    yhat = np.exp(yhat) - 1\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n",
    "    return \"rmspe\", rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store = pd.read_csv('store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>620.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>29910.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
       "0      1         c          a               1270.0                        9.0   \n",
       "1      2         a          a                570.0                       11.0   \n",
       "2      3         a          a              14130.0                       12.0   \n",
       "3      4         c          c                620.0                        9.0   \n",
       "4      5         a          a              29910.0                        4.0   \n",
       "\n",
       "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
       "0                    2008.0       0              NaN              NaN   \n",
       "1                    2007.0       1             13.0           2010.0   \n",
       "2                    2006.0       1             14.0           2011.0   \n",
       "3                    2009.0       0              NaN              NaN   \n",
       "4                    2015.0       0              NaN              NaN   \n",
       "\n",
       "     PromoInterval  \n",
       "0              NaN  \n",
       "1  Jan,Apr,Jul,Oct  \n",
       "2  Jan,Apr,Jul,Oct  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          5  2015-07-31   5263        555     1      1            0   \n",
       "1      2          5  2015-07-31   6064        625     1      1            0   \n",
       "2      3          5  2015-07-31   8314        821     1      1            0   \n",
       "3      4          5  2015-07-31  13995       1498     1      1            0   \n",
       "4      5          5  2015-07-31   4822        559     1      1            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Store  DayOfWeek        Date  Open  Promo StateHoliday  SchoolHoliday\n",
       "0   1      1          4  2015-09-17   1.0      1            0              0\n",
       "1   2      3          4  2015-09-17   1.0      1            0              0\n",
       "2   3      7          4  2015-09-17   1.0      1            0              0\n",
       "3   4      8          4  2015-09-17   1.0      1            0              0\n",
       "4   5      9          4  2015-09-17   1.0      1            0              0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "        加载数据，设定数值型和非数值型数据\n",
    "    \"\"\"\n",
    "    store = pd.read_csv('store.csv')\n",
    "    train_org = pd.read_csv('train.csv',dtype={'StateHoliday':pd.np.string_})\n",
    "    test_org = pd.read_csv('test.csv',dtype={'StateHoliday':pd.np.string_})\n",
    "    train = pd.merge(train_org,store, on='Store', how='left')\n",
    "    test = pd.merge(test_org,store, on='Store', how='left')\n",
    "    features = test.columns.tolist()\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    features_numeric = test.select_dtypes(include=numerics).columns.tolist()\n",
    "    features_non_numeric = [f for f in features if f not in features_numeric]\n",
    "    return (train,test,features,features_non_numeric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据与特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(train,test,features,features_non_numeric):\n",
    "    \"\"\"\n",
    "        Feature engineering and selection.\n",
    "    \"\"\"\n",
    "    # # FEATURE ENGINEERING\n",
    "    train = train[train['Sales'] > 0]\n",
    "\n",
    "    for data in [train,test]:\n",
    "        # year month day\n",
    "        data['year'] = data.Date.apply(lambda x: x.split('-')[0])\n",
    "        data['year'] = data['year'].astype(float)\n",
    "        data['month'] = data.Date.apply(lambda x: x.split('-')[1])\n",
    "        data['month'] = data['month'].astype(float)\n",
    "        data['day'] = data.Date.apply(lambda x: x.split('-')[2])\n",
    "        data['day'] = data['day'].astype(float)\n",
    "\n",
    "        # promo interval \"Jan,Apr,Jul,Oct\"\n",
    "        data['promojan'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Jan\" in x else 0)\n",
    "        #TypeError: argument of type 'float' is not iterable 为什么使用isinstance(x,float)\n",
    "        data['promofeb'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Feb\" in x else 0)\n",
    "        data['promomar'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Mar\" in x else 0)\n",
    "        data['promoapr'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Apr\" in x else 0)\n",
    "        data['promomay'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"May\" in x else 0)\n",
    "        data['promojun'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Jun\" in x else 0)\n",
    "        data['promojul'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Jul\" in x else 0)\n",
    "        data['promoaug'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Aug\" in x else 0)\n",
    "        data['promosep'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Sep\" in x else 0)\n",
    "        data['promooct'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Oct\" in x else 0)\n",
    "        data['promonov'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Nov\" in x else 0)\n",
    "        data['promodec'] = data.PromoInterval.apply(lambda x: 0 if isinstance(x, float) else 1 if \"Dec\" in x else 0)\n",
    "\n",
    "    # # Features set.\n",
    "    noisy_features = [myid,'Date']\n",
    "    features = [c for c in features if c not in noisy_features]\n",
    "    features_non_numeric = [c for c in features_non_numeric if c not in noisy_features]\n",
    "    features.extend(['year','month','day'])\n",
    "    # Fill NA\n",
    "    class DataFrameImputer(TransformerMixin):\n",
    "        # http://stackoverflow.com/questions/25239958/impute-categorical-missing-values-in-scikit-learn\n",
    "        def __init__(self):\n",
    "            \"\"\"Impute missing values.\n",
    "            Columns of dtype object are imputed with the most frequent value\n",
    "            in column.\n",
    "            Columns of other types are imputed with mean of column.\n",
    "            \"\"\"\n",
    "        def fit(self, X, y=None):\n",
    "            self.fill = pd.Series([X[c].value_counts().index[0] # mode\n",
    "                if X[c].dtype == np.dtype('O') else X[c].mean() for c in X], # mean\n",
    "                index=X.columns)\n",
    "            return self\n",
    "        def transform(self, X, y=None):\n",
    "            return X.fillna(self.fill)\n",
    "    train = DataFrameImputer().fit_transform(train)\n",
    "    test = DataFrameImputer().fit_transform(test)\n",
    "    # Pre-processing non-numberic values\n",
    "    le = LabelEncoder()\n",
    "    for col in features_non_numeric:\n",
    "        le.fit(list(train[col])+list(test[col]))\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])\n",
    "    # LR和神经网络这种模型都对输入数据的幅度极度敏感，请先做归一化操作\n",
    "    scaler = StandardScaler()\n",
    "    for col in set(features) - set(features_non_numeric) - \\\n",
    "      set([]): # TODO: add what not to scale\n",
    "        scaler.fit(list(train[col])+list(test[col]))\n",
    "        train[col] = scaler.transform(train[col])\n",
    "        test[col] = scaler.transform(test[col])\n",
    "    return (train,test,features,features_non_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练与分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "predict_result = log(y+1)\n",
    "y = e^(predict_result)-1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def XGB_native(train,test,features,features_non_numeric):\n",
    "    depth = 6\n",
    "    eta = 0.01\n",
    "    ntrees = 8000\n",
    "    mcw = 3\n",
    "    params = {\"objective\": \"reg:linear\",\n",
    "              \"booster\": \"gbtree\",\n",
    "              \"eta\": eta,\n",
    "              \"max_depth\": depth,\n",
    "              \"min_child_weight\": mcw,\n",
    "              \"subsample\": 0.7,\n",
    "              \"colsample_bytree\": 0.7,\n",
    "              \"silent\": 1\n",
    "              }\n",
    "    print \"Running with params: \" + str(params)\n",
    "    print \"Running with ntrees: \" + str(ntrees)\n",
    "    print \"Running with features: \" + str(features)\n",
    "\n",
    "    # Train model with local split\n",
    "    tsize = 0.05\n",
    "    X_train, X_test = cross_validation.train_test_split(train, test_size=tsize)\n",
    "    dtrain = xgb.DMatrix(X_train[features], np.log(X_train[goal] + 1))\n",
    "    dvalid = xgb.DMatrix(X_test[features], np.log(X_test[goal] + 1))\n",
    "    watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    gbm = xgb.train(params, dtrain, ntrees, evals=watchlist, early_stopping_rounds=100, feval=rmspe_xg, verbose_eval=True)\n",
    "    train_probs = gbm.predict(xgb.DMatrix(X_test[features]))\n",
    "    indices = train_probs < 0\n",
    "    train_probs[indices] = 0\n",
    "    error = rmspe(np.exp(train_probs) - 1, X_test[goal].values)\n",
    "    print error\n",
    "\n",
    "    # Predict and Export\n",
    "    test_probs = gbm.predict(xgb.DMatrix(test[features]))\n",
    "    indices = test_probs < 0\n",
    "    test_probs[indices] = 0\n",
    "    submission = pd.DataFrame({myid: test[myid], goal: np.exp(test_probs) - 1})\n",
    "    if not os.path.exists('result/'):\n",
    "        os.makedirs('result/')\n",
    "    submission.to_csv(\"./result/dat-xgb_d%s_eta%s_ntree%s_mcw%s_tsize%s.csv\" % (str(depth),str(eta),str(ntrees),str(mcw),str(tsize)) , index=False)\n",
    "    # Feature importance\n",
    "    if plot:\n",
    "      outfile = open('xgb.fmap', 'w')\n",
    "      i = 0\n",
    "      for feat in features:\n",
    "          outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "          i = i + 1\n",
    "      outfile.close()\n",
    "      importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "      importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "      df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "      df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "      # Plotitup\n",
    "      plt.figure()\n",
    "      df.plot()\n",
    "      df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(25, 15))\n",
    "      plt.title('XGBoost Feature Importance')\n",
    "      plt.xlabel('relative importance')\n",
    "      plt.gcf().savefig('Feature_Importance_xgb_d%s_eta%s_ntree%s_mcw%s_tsize%s.png' % (str(depth),str(eta),str(ntrees),str(mcw),str(tsize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 载入数据中...\n",
      "=> 处理数据与特征工程...\n",
      "=> 使用XGBoost建模...\n",
      "Running with params: {'subsample': 0.7, 'eta': 0.01, 'colsample_bytree': 0.7, 'silent': 1, 'objective': 'reg:linear', 'max_depth': 6, 'min_child_weight': 3, 'booster': 'gbtree'}\n",
      "Running with ntrees: 8000\n",
      "Running with features: ['Store', 'DayOfWeek', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval', 'year', 'month', 'day']\n",
      "[0]\teval-rmspe:0.999864\ttrain-rmspe:0.999864\n",
      "Multiple eval metrics have been passed: 'train-rmspe' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmspe hasn't improved in 100 rounds.\n",
      "[1]\teval-rmspe:0.999838\ttrain-rmspe:0.999837\n",
      "[2]\teval-rmspe:0.99981\ttrain-rmspe:0.999809\n",
      "[3]\teval-rmspe:0.999779\ttrain-rmspe:0.999779\n",
      "[4]\teval-rmspe:0.999747\ttrain-rmspe:0.999747\n",
      "[5]\teval-rmspe:0.999713\ttrain-rmspe:0.999712\n",
      "[6]\teval-rmspe:0.999676\ttrain-rmspe:0.999675\n",
      "[7]\teval-rmspe:0.999636\ttrain-rmspe:0.999636\n",
      "[8]\teval-rmspe:0.999594\ttrain-rmspe:0.999594\n",
      "[9]\teval-rmspe:0.999549\ttrain-rmspe:0.999548\n",
      "[10]\teval-rmspe:0.999501\ttrain-rmspe:0.9995\n",
      "[11]\teval-rmspe:0.99945\ttrain-rmspe:0.999449\n",
      "[12]\teval-rmspe:0.999395\ttrain-rmspe:0.999394\n",
      "[13]\teval-rmspe:0.999337\ttrain-rmspe:0.999336\n",
      "[14]\teval-rmspe:0.999275\ttrain-rmspe:0.999274\n",
      "[15]\teval-rmspe:0.99921\ttrain-rmspe:0.999209\n",
      "[16]\teval-rmspe:0.99914\ttrain-rmspe:0.999139\n",
      "[17]\teval-rmspe:0.999066\ttrain-rmspe:0.999065\n",
      "[18]\teval-rmspe:0.998988\ttrain-rmspe:0.998986\n",
      "[19]\teval-rmspe:0.998904\ttrain-rmspe:0.998903\n",
      "[20]\teval-rmspe:0.998816\ttrain-rmspe:0.998815\n",
      "[21]\teval-rmspe:0.998723\ttrain-rmspe:0.998721\n",
      "[22]\teval-rmspe:0.998624\ttrain-rmspe:0.998622\n",
      "[23]\teval-rmspe:0.99852\ttrain-rmspe:0.998518\n",
      "[24]\teval-rmspe:0.99841\ttrain-rmspe:0.998408\n",
      "[25]\teval-rmspe:0.998294\ttrain-rmspe:0.998291\n",
      "[26]\teval-rmspe:0.998171\ttrain-rmspe:0.998168\n",
      "[27]\teval-rmspe:0.998041\ttrain-rmspe:0.998039\n",
      "[28]\teval-rmspe:0.997905\ttrain-rmspe:0.997902\n",
      "[29]\teval-rmspe:0.997762\ttrain-rmspe:0.997759\n",
      "[30]\teval-rmspe:0.99761\ttrain-rmspe:0.997607\n",
      "[31]\teval-rmspe:0.997451\ttrain-rmspe:0.997448\n",
      "[32]\teval-rmspe:0.997285\ttrain-rmspe:0.997281\n",
      "[33]\teval-rmspe:0.997109\ttrain-rmspe:0.997105\n",
      "[34]\teval-rmspe:0.996925\ttrain-rmspe:0.996921\n",
      "[35]\teval-rmspe:0.996732\ttrain-rmspe:0.996728\n",
      "[36]\teval-rmspe:0.996529\ttrain-rmspe:0.996525\n",
      "[37]\teval-rmspe:0.996317\ttrain-rmspe:0.996312\n",
      "[38]\teval-rmspe:0.996095\ttrain-rmspe:0.99609\n",
      "[39]\teval-rmspe:0.995862\ttrain-rmspe:0.995857\n",
      "[40]\teval-rmspe:0.995619\ttrain-rmspe:0.995614\n",
      "[41]\teval-rmspe:0.995364\ttrain-rmspe:0.995359\n",
      "[42]\teval-rmspe:0.995098\ttrain-rmspe:0.995092\n",
      "[43]\teval-rmspe:0.994821\ttrain-rmspe:0.994814\n",
      "[44]\teval-rmspe:0.994531\ttrain-rmspe:0.994524\n",
      "[45]\teval-rmspe:0.994228\ttrain-rmspe:0.994221\n",
      "[46]\teval-rmspe:0.993913\ttrain-rmspe:0.993905\n",
      "[47]\teval-rmspe:0.993584\ttrain-rmspe:0.993576\n",
      "[48]\teval-rmspe:0.993242\ttrain-rmspe:0.993234\n",
      "[49]\teval-rmspe:0.992885\ttrain-rmspe:0.992877\n",
      "[50]\teval-rmspe:0.992514\ttrain-rmspe:0.992505\n",
      "[51]\teval-rmspe:0.992129\ttrain-rmspe:0.992119\n",
      "[52]\teval-rmspe:0.991728\ttrain-rmspe:0.991718\n",
      "[53]\teval-rmspe:0.991311\ttrain-rmspe:0.991301\n",
      "[54]\teval-rmspe:0.990878\ttrain-rmspe:0.990867\n",
      "[55]\teval-rmspe:0.990429\ttrain-rmspe:0.990418\n",
      "[56]\teval-rmspe:0.989962\ttrain-rmspe:0.98995\n",
      "[57]\teval-rmspe:0.989478\ttrain-rmspe:0.989466\n",
      "[58]\teval-rmspe:0.988977\ttrain-rmspe:0.988964\n",
      "[59]\teval-rmspe:0.988457\ttrain-rmspe:0.988444\n",
      "[60]\teval-rmspe:0.987919\ttrain-rmspe:0.987905\n",
      "[61]\teval-rmspe:0.987362\ttrain-rmspe:0.987348\n",
      "[62]\teval-rmspe:0.986785\ttrain-rmspe:0.98677\n",
      "[63]\teval-rmspe:0.986188\ttrain-rmspe:0.986172\n",
      "[64]\teval-rmspe:0.985572\ttrain-rmspe:0.985556\n",
      "[65]\teval-rmspe:0.984934\ttrain-rmspe:0.984918\n",
      "[66]\teval-rmspe:0.984276\ttrain-rmspe:0.984259\n",
      "[67]\teval-rmspe:0.983597\ttrain-rmspe:0.98358\n",
      "[68]\teval-rmspe:0.982896\ttrain-rmspe:0.982877\n",
      "[69]\teval-rmspe:0.982173\ttrain-rmspe:0.982154\n",
      "[70]\teval-rmspe:0.981427\ttrain-rmspe:0.981408\n",
      "[71]\teval-rmspe:0.980658\ttrain-rmspe:0.980638\n",
      "[72]\teval-rmspe:0.979865\ttrain-rmspe:0.979845\n",
      "[73]\teval-rmspe:0.979049\ttrain-rmspe:0.979027\n",
      "[74]\teval-rmspe:0.978209\ttrain-rmspe:0.978187\n",
      "[75]\teval-rmspe:0.977343\ttrain-rmspe:0.97732\n",
      "[76]\teval-rmspe:0.976454\ttrain-rmspe:0.976431\n",
      "[77]\teval-rmspe:0.97554\ttrain-rmspe:0.975516\n",
      "[78]\teval-rmspe:0.974602\ttrain-rmspe:0.974577\n",
      "[79]\teval-rmspe:0.973635\ttrain-rmspe:0.97361\n",
      "[80]\teval-rmspe:0.972644\ttrain-rmspe:0.972618\n",
      "[81]\teval-rmspe:0.971625\ttrain-rmspe:0.971599\n",
      "[82]\teval-rmspe:0.970581\ttrain-rmspe:0.970554\n",
      "[83]\teval-rmspe:0.969508\ttrain-rmspe:0.96948\n",
      "[84]\teval-rmspe:0.968408\ttrain-rmspe:0.96838\n",
      "[85]\teval-rmspe:0.967281\ttrain-rmspe:0.967252\n",
      "[86]\teval-rmspe:0.966125\ttrain-rmspe:0.966095\n",
      "[87]\teval-rmspe:0.964941\ttrain-rmspe:0.964911\n",
      "[88]\teval-rmspe:0.963728\ttrain-rmspe:0.963697\n",
      "[89]\teval-rmspe:0.962488\ttrain-rmspe:0.962456\n",
      "[90]\teval-rmspe:0.961218\ttrain-rmspe:0.961185\n",
      "[91]\teval-rmspe:0.959917\ttrain-rmspe:0.959884\n",
      "[92]\teval-rmspe:0.958588\ttrain-rmspe:0.958556\n",
      "[93]\teval-rmspe:0.957229\ttrain-rmspe:0.957195\n",
      "[94]\teval-rmspe:0.955839\ttrain-rmspe:0.955806\n",
      "[95]\teval-rmspe:0.95442\ttrain-rmspe:0.954385\n",
      "[96]\teval-rmspe:0.952969\ttrain-rmspe:0.952934\n",
      "[97]\teval-rmspe:0.951489\ttrain-rmspe:0.951454\n",
      "[98]\teval-rmspe:0.949978\ttrain-rmspe:0.949943\n",
      "[99]\teval-rmspe:0.948435\ttrain-rmspe:0.948399\n",
      "[100]\teval-rmspe:0.946863\ttrain-rmspe:0.946827\n",
      "[101]\teval-rmspe:0.945258\ttrain-rmspe:0.945222\n",
      "[102]\teval-rmspe:0.943623\ttrain-rmspe:0.943588\n",
      "[103]\teval-rmspe:0.941956\ttrain-rmspe:0.941921\n",
      "[104]\teval-rmspe:0.940258\ttrain-rmspe:0.940224\n",
      "[105]\teval-rmspe:0.938527\ttrain-rmspe:0.938492\n",
      "[106]\teval-rmspe:0.936764\ttrain-rmspe:0.936729\n",
      "[107]\teval-rmspe:0.934968\ttrain-rmspe:0.934933\n",
      "[108]\teval-rmspe:0.933143\ttrain-rmspe:0.933109\n",
      "[109]\teval-rmspe:0.931288\ttrain-rmspe:0.931254\n",
      "[110]\teval-rmspe:0.9294\ttrain-rmspe:0.929366\n",
      "[111]\teval-rmspe:0.927479\ttrain-rmspe:0.927445\n",
      "[112]\teval-rmspe:0.925526\ttrain-rmspe:0.925494\n",
      "[113]\teval-rmspe:0.923541\ttrain-rmspe:0.923509\n",
      "[114]\teval-rmspe:0.921521\ttrain-rmspe:0.92149\n",
      "[115]\teval-rmspe:0.919474\ttrain-rmspe:0.919444\n",
      "[116]\teval-rmspe:0.917394\ttrain-rmspe:0.917365\n",
      "[117]\teval-rmspe:0.915284\ttrain-rmspe:0.915257\n",
      "[118]\teval-rmspe:0.913143\ttrain-rmspe:0.913116\n",
      "[119]\teval-rmspe:0.91097\ttrain-rmspe:0.910946\n",
      "[120]\teval-rmspe:0.908764\ttrain-rmspe:0.908742\n",
      "[121]\teval-rmspe:0.90653\ttrain-rmspe:0.906509\n",
      "[122]\teval-rmspe:0.904265\ttrain-rmspe:0.904246\n",
      "[123]\teval-rmspe:0.90197\ttrain-rmspe:0.901952\n",
      "[124]\teval-rmspe:0.899642\ttrain-rmspe:0.899628\n",
      "[125]\teval-rmspe:0.897285\ttrain-rmspe:0.897274\n",
      "[126]\teval-rmspe:0.894896\ttrain-rmspe:0.894887\n",
      "[127]\teval-rmspe:0.892476\ttrain-rmspe:0.89247\n",
      "[128]\teval-rmspe:0.890025\ttrain-rmspe:0.890023\n",
      "[129]\teval-rmspe:0.887547\ttrain-rmspe:0.887548\n",
      "[130]\teval-rmspe:0.885037\ttrain-rmspe:0.885041\n",
      "[131]\teval-rmspe:0.882502\ttrain-rmspe:0.88251\n",
      "[132]\teval-rmspe:0.879932\ttrain-rmspe:0.879944\n",
      "[133]\teval-rmspe:0.877336\ttrain-rmspe:0.877352\n",
      "[134]\teval-rmspe:0.874712\ttrain-rmspe:0.874732\n",
      "[135]\teval-rmspe:0.872064\ttrain-rmspe:0.872089\n",
      "[136]\teval-rmspe:0.869382\ttrain-rmspe:0.869411\n",
      "[137]\teval-rmspe:0.866674\ttrain-rmspe:0.866708\n",
      "[138]\teval-rmspe:0.863938\ttrain-rmspe:0.863978\n",
      "[139]\teval-rmspe:0.861176\ttrain-rmspe:0.861221\n",
      "[140]\teval-rmspe:0.858387\ttrain-rmspe:0.858437\n",
      "[141]\teval-rmspe:0.85557\ttrain-rmspe:0.855626\n",
      "[142]\teval-rmspe:0.852727\ttrain-rmspe:0.852788\n",
      "[143]\teval-rmspe:0.84986\ttrain-rmspe:0.849926\n",
      "[144]\teval-rmspe:0.84697\ttrain-rmspe:0.847042\n",
      "[145]\teval-rmspe:0.844054\ttrain-rmspe:0.844134\n",
      "[146]\teval-rmspe:0.841111\ttrain-rmspe:0.8412\n",
      "[147]\teval-rmspe:0.838147\ttrain-rmspe:0.838245\n",
      "[148]\teval-rmspe:0.835159\ttrain-rmspe:0.835264\n",
      "[149]\teval-rmspe:0.832148\ttrain-rmspe:0.832263\n",
      "[150]\teval-rmspe:0.829114\ttrain-rmspe:0.82924\n",
      "[151]\teval-rmspe:0.826057\ttrain-rmspe:0.826194\n",
      "[152]\teval-rmspe:0.822976\ttrain-rmspe:0.823124\n",
      "[153]\teval-rmspe:0.819876\ttrain-rmspe:0.820035\n",
      "[154]\teval-rmspe:0.816753\ttrain-rmspe:0.816924\n",
      "[155]\teval-rmspe:0.813611\ttrain-rmspe:0.813793\n",
      "[156]\teval-rmspe:0.810445\ttrain-rmspe:0.810639\n",
      "[157]\teval-rmspe:0.807265\ttrain-rmspe:0.807472\n",
      "[158]\teval-rmspe:0.804064\ttrain-rmspe:0.804284\n",
      "[159]\teval-rmspe:0.800846\ttrain-rmspe:0.801079\n",
      "[160]\teval-rmspe:0.797607\ttrain-rmspe:0.797855\n",
      "[161]\teval-rmspe:0.794351\ttrain-rmspe:0.794612\n",
      "[162]\teval-rmspe:0.79108\ttrain-rmspe:0.791355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163]\teval-rmspe:0.787788\ttrain-rmspe:0.78808\n",
      "[164]\teval-rmspe:0.784484\ttrain-rmspe:0.784792\n",
      "[165]\teval-rmspe:0.78116\ttrain-rmspe:0.781483\n",
      "[166]\teval-rmspe:0.777822\ttrain-rmspe:0.778159\n",
      "[167]\teval-rmspe:0.774469\ttrain-rmspe:0.774823\n",
      "[168]\teval-rmspe:0.771098\ttrain-rmspe:0.77147\n",
      "[169]\teval-rmspe:0.767716\ttrain-rmspe:0.768103\n",
      "[170]\teval-rmspe:0.764321\ttrain-rmspe:0.764729\n",
      "[171]\teval-rmspe:0.760912\ttrain-rmspe:0.761338\n",
      "[172]\teval-rmspe:0.757492\ttrain-rmspe:0.757939\n",
      "[173]\teval-rmspe:0.754066\ttrain-rmspe:0.754533\n",
      "[174]\teval-rmspe:0.750628\ttrain-rmspe:0.751115\n",
      "[175]\teval-rmspe:0.747177\ttrain-rmspe:0.747687\n",
      "[176]\teval-rmspe:0.743715\ttrain-rmspe:0.74425\n",
      "[177]\teval-rmspe:0.740243\ttrain-rmspe:0.740802\n",
      "[178]\teval-rmspe:0.736767\ttrain-rmspe:0.737352\n",
      "[179]\teval-rmspe:0.733275\ttrain-rmspe:0.733883\n",
      "[180]\teval-rmspe:0.729777\ttrain-rmspe:0.730408\n",
      "[181]\teval-rmspe:0.726273\ttrain-rmspe:0.726932\n",
      "[182]\teval-rmspe:0.72276\ttrain-rmspe:0.723447\n",
      "[183]\teval-rmspe:0.719242\ttrain-rmspe:0.719959\n",
      "[184]\teval-rmspe:0.71572\ttrain-rmspe:0.716464\n",
      "[185]\teval-rmspe:0.712193\ttrain-rmspe:0.712962\n",
      "[186]\teval-rmspe:0.708658\ttrain-rmspe:0.709458\n",
      "[187]\teval-rmspe:0.70512\ttrain-rmspe:0.705951\n",
      "[188]\teval-rmspe:0.701579\ttrain-rmspe:0.70244\n",
      "[189]\teval-rmspe:0.698033\ttrain-rmspe:0.698928\n",
      "[190]\teval-rmspe:0.694485\ttrain-rmspe:0.69541\n",
      "[191]\teval-rmspe:0.690935\ttrain-rmspe:0.691895\n",
      "[192]\teval-rmspe:0.687384\ttrain-rmspe:0.688379\n",
      "[193]\teval-rmspe:0.683832\ttrain-rmspe:0.684862\n",
      "[194]\teval-rmspe:0.680277\ttrain-rmspe:0.681345\n",
      "[195]\teval-rmspe:0.676723\ttrain-rmspe:0.677829\n",
      "[196]\teval-rmspe:0.673178\ttrain-rmspe:0.674319\n",
      "[197]\teval-rmspe:0.669628\ttrain-rmspe:0.670806\n",
      "[198]\teval-rmspe:0.666075\ttrain-rmspe:0.667295\n",
      "[199]\teval-rmspe:0.662527\ttrain-rmspe:0.663789\n",
      "[200]\teval-rmspe:0.65898\ttrain-rmspe:0.660282\n",
      "[201]\teval-rmspe:0.655435\ttrain-rmspe:0.65678\n",
      "[202]\teval-rmspe:0.651892\ttrain-rmspe:0.653285\n",
      "[203]\teval-rmspe:0.648356\ttrain-rmspe:0.649795\n",
      "[204]\teval-rmspe:0.644826\ttrain-rmspe:0.646311\n",
      "[205]\teval-rmspe:0.641298\ttrain-rmspe:0.64283\n",
      "[206]\teval-rmspe:0.637776\ttrain-rmspe:0.639357\n",
      "[207]\teval-rmspe:0.63426\ttrain-rmspe:0.63589\n",
      "[208]\teval-rmspe:0.630748\ttrain-rmspe:0.63243\n",
      "[209]\teval-rmspe:0.627244\ttrain-rmspe:0.628979\n",
      "[210]\teval-rmspe:0.623745\ttrain-rmspe:0.625532\n",
      "[211]\teval-rmspe:0.620258\ttrain-rmspe:0.622096\n",
      "[212]\teval-rmspe:0.616777\ttrain-rmspe:0.618672\n",
      "[213]\teval-rmspe:0.613307\ttrain-rmspe:0.615255\n",
      "[214]\teval-rmspe:0.609847\ttrain-rmspe:0.611852\n",
      "[215]\teval-rmspe:0.606398\ttrain-rmspe:0.608462\n",
      "[216]\teval-rmspe:0.602953\ttrain-rmspe:0.605076\n",
      "[217]\teval-rmspe:0.599523\ttrain-rmspe:0.601704\n",
      "[218]\teval-rmspe:0.596101\ttrain-rmspe:0.598343\n",
      "[219]\teval-rmspe:0.59269\ttrain-rmspe:0.594988\n",
      "[220]\teval-rmspe:0.589291\ttrain-rmspe:0.591652\n",
      "[221]\teval-rmspe:0.585909\ttrain-rmspe:0.58833\n",
      "[222]\teval-rmspe:0.582535\ttrain-rmspe:0.585023\n",
      "[223]\teval-rmspe:0.579174\ttrain-rmspe:0.581731\n",
      "[224]\teval-rmspe:0.575827\ttrain-rmspe:0.578452\n",
      "[225]\teval-rmspe:0.572496\ttrain-rmspe:0.575186\n",
      "[226]\teval-rmspe:0.569177\ttrain-rmspe:0.571939\n",
      "[227]\teval-rmspe:0.565873\ttrain-rmspe:0.568705\n",
      "[228]\teval-rmspe:0.562583\ttrain-rmspe:0.565478\n",
      "[229]\teval-rmspe:0.559309\ttrain-rmspe:0.56228\n",
      "[230]\teval-rmspe:0.556052\ttrain-rmspe:0.559097\n",
      "[231]\teval-rmspe:0.552812\ttrain-rmspe:0.555934\n",
      "[232]\teval-rmspe:0.549585\ttrain-rmspe:0.552781\n",
      "[233]\teval-rmspe:0.546371\ttrain-rmspe:0.549649\n",
      "[234]\teval-rmspe:0.543179\ttrain-rmspe:0.546538\n",
      "[235]\teval-rmspe:0.540003\ttrain-rmspe:0.543446\n",
      "[236]\teval-rmspe:0.536847\ttrain-rmspe:0.54037\n",
      "[237]\teval-rmspe:0.533708\ttrain-rmspe:0.537314\n",
      "[238]\teval-rmspe:0.530588\ttrain-rmspe:0.534278\n",
      "[239]\teval-rmspe:0.527483\ttrain-rmspe:0.531259\n",
      "[240]\teval-rmspe:0.524398\ttrain-rmspe:0.528261\n",
      "[241]\teval-rmspe:0.521337\ttrain-rmspe:0.525289\n",
      "[242]\teval-rmspe:0.518284\ttrain-rmspe:0.522321\n",
      "[243]\teval-rmspe:0.515259\ttrain-rmspe:0.519384\n",
      "[244]\teval-rmspe:0.512255\ttrain-rmspe:0.516473\n",
      "[245]\teval-rmspe:0.509267\ttrain-rmspe:0.513579\n",
      "[246]\teval-rmspe:0.506286\ttrain-rmspe:0.510694\n",
      "[247]\teval-rmspe:0.50334\ttrain-rmspe:0.507843\n",
      "[248]\teval-rmspe:0.500419\ttrain-rmspe:0.505019\n",
      "[249]\teval-rmspe:0.497518\ttrain-rmspe:0.502217\n",
      "[250]\teval-rmspe:0.494637\ttrain-rmspe:0.499441\n",
      "[251]\teval-rmspe:0.491781\ttrain-rmspe:0.496687\n",
      "[252]\teval-rmspe:0.488945\ttrain-rmspe:0.493957\n",
      "[253]\teval-rmspe:0.486133\ttrain-rmspe:0.49125\n",
      "[254]\teval-rmspe:0.483345\ttrain-rmspe:0.488567\n",
      "[255]\teval-rmspe:0.480582\ttrain-rmspe:0.485907\n",
      "[256]\teval-rmspe:0.477822\ttrain-rmspe:0.483249\n",
      "[257]\teval-rmspe:0.475101\ttrain-rmspe:0.480638\n",
      "[258]\teval-rmspe:0.472394\ttrain-rmspe:0.478045\n",
      "[259]\teval-rmspe:0.469723\ttrain-rmspe:0.475484\n",
      "[260]\teval-rmspe:0.467075\ttrain-rmspe:0.472948\n",
      "[261]\teval-rmspe:0.464434\ttrain-rmspe:0.470422\n",
      "[262]\teval-rmspe:0.461831\ttrain-rmspe:0.467929\n",
      "[263]\teval-rmspe:0.459255\ttrain-rmspe:0.465469\n",
      "[264]\teval-rmspe:0.456701\ttrain-rmspe:0.463018\n",
      "[265]\teval-rmspe:0.454172\ttrain-rmspe:0.460604\n",
      "[266]\teval-rmspe:0.451658\ttrain-rmspe:0.458213\n",
      "[267]\teval-rmspe:0.44918\ttrain-rmspe:0.455853\n",
      "[268]\teval-rmspe:0.44673\ttrain-rmspe:0.453518\n",
      "[269]\teval-rmspe:0.444304\ttrain-rmspe:0.451211\n",
      "[270]\teval-rmspe:0.441893\ttrain-rmspe:0.448928\n",
      "[271]\teval-rmspe:0.439506\ttrain-rmspe:0.446667\n",
      "[272]\teval-rmspe:0.437141\ttrain-rmspe:0.444428\n",
      "[273]\teval-rmspe:0.434819\ttrain-rmspe:0.442233\n",
      "[274]\teval-rmspe:0.43252\ttrain-rmspe:0.440064\n",
      "[275]\teval-rmspe:0.430229\ttrain-rmspe:0.437909\n",
      "[276]\teval-rmspe:0.427958\ttrain-rmspe:0.435769\n",
      "[277]\teval-rmspe:0.425741\ttrain-rmspe:0.433682\n",
      "[278]\teval-rmspe:0.423543\ttrain-rmspe:0.431614\n",
      "[279]\teval-rmspe:0.42136\ttrain-rmspe:0.429561\n",
      "[280]\teval-rmspe:0.419196\ttrain-rmspe:0.427525\n",
      "[281]\teval-rmspe:0.417053\ttrain-rmspe:0.425507\n",
      "[282]\teval-rmspe:0.41496\ttrain-rmspe:0.423548\n",
      "[283]\teval-rmspe:0.412838\ttrain-rmspe:0.421558\n",
      "[284]\teval-rmspe:0.410793\ttrain-rmspe:0.419655\n",
      "[285]\teval-rmspe:0.408766\ttrain-rmspe:0.417771\n",
      "[286]\teval-rmspe:0.406776\ttrain-rmspe:0.415918\n",
      "[287]\teval-rmspe:0.404809\ttrain-rmspe:0.414088\n",
      "[288]\teval-rmspe:0.402856\ttrain-rmspe:0.41227\n",
      "[289]\teval-rmspe:0.400947\ttrain-rmspe:0.410497\n",
      "[290]\teval-rmspe:0.399061\ttrain-rmspe:0.408745\n",
      "[291]\teval-rmspe:0.39719\ttrain-rmspe:0.407015\n",
      "[292]\teval-rmspe:0.395356\ttrain-rmspe:0.405319\n",
      "[293]\teval-rmspe:0.393534\ttrain-rmspe:0.403634\n",
      "[294]\teval-rmspe:0.391727\ttrain-rmspe:0.401974\n",
      "[295]\teval-rmspe:0.389971\ttrain-rmspe:0.400344\n",
      "[296]\teval-rmspe:0.388212\ttrain-rmspe:0.398718\n",
      "[297]\teval-rmspe:0.386505\ttrain-rmspe:0.397138\n",
      "[298]\teval-rmspe:0.384811\ttrain-rmspe:0.395593\n",
      "[299]\teval-rmspe:0.383148\ttrain-rmspe:0.394073\n",
      "[300]\teval-rmspe:0.381499\ttrain-rmspe:0.392577\n",
      "[301]\teval-rmspe:0.379862\ttrain-rmspe:0.391079\n",
      "[302]\teval-rmspe:0.378266\ttrain-rmspe:0.389623\n",
      "[303]\teval-rmspe:0.376664\ttrain-rmspe:0.388163\n",
      "[304]\teval-rmspe:0.375125\ttrain-rmspe:0.386765\n",
      "[305]\teval-rmspe:0.373618\ttrain-rmspe:0.385407\n",
      "[306]\teval-rmspe:0.372124\ttrain-rmspe:0.384054\n",
      "[307]\teval-rmspe:0.37067\ttrain-rmspe:0.382748\n",
      "[308]\teval-rmspe:0.369202\ttrain-rmspe:0.381423\n",
      "[309]\teval-rmspe:0.367794\ttrain-rmspe:0.380162\n",
      "[310]\teval-rmspe:0.366373\ttrain-rmspe:0.378882\n",
      "[311]\teval-rmspe:0.364993\ttrain-rmspe:0.37764\n",
      "[312]\teval-rmspe:0.363667\ttrain-rmspe:0.376456\n",
      "[313]\teval-rmspe:0.362355\ttrain-rmspe:0.375288\n",
      "[314]\teval-rmspe:0.361061\ttrain-rmspe:0.374141\n",
      "[315]\teval-rmspe:0.359802\ttrain-rmspe:0.373025\n",
      "[316]\teval-rmspe:0.358513\ttrain-rmspe:0.37187\n",
      "[317]\teval-rmspe:0.357288\ttrain-rmspe:0.370789\n",
      "[318]\teval-rmspe:0.356099\ttrain-rmspe:0.369741\n",
      "[319]\teval-rmspe:0.354905\ttrain-rmspe:0.368667\n",
      "[320]\teval-rmspe:0.353724\ttrain-rmspe:0.367625\n",
      "[321]\teval-rmspe:0.352585\ttrain-rmspe:0.366632\n",
      "[322]\teval-rmspe:0.351471\ttrain-rmspe:0.365672\n",
      "[323]\teval-rmspe:0.350362\ttrain-rmspe:0.364706\n",
      "[324]\teval-rmspe:0.349278\ttrain-rmspe:0.363764\n",
      "[325]\teval-rmspe:0.348192\ttrain-rmspe:0.362815\n",
      "[326]\teval-rmspe:0.34711\ttrain-rmspe:0.36184\n",
      "[327]\teval-rmspe:0.346117\ttrain-rmspe:0.360988\n",
      "[328]\teval-rmspe:0.345112\ttrain-rmspe:0.360117\n",
      "[329]\teval-rmspe:0.344142\ttrain-rmspe:0.359284\n",
      "[330]\teval-rmspe:0.34317\ttrain-rmspe:0.358447\n",
      "[331]\teval-rmspe:0.342214\ttrain-rmspe:0.357619\n",
      "[332]\teval-rmspe:0.341306\ttrain-rmspe:0.356829\n",
      "[333]\teval-rmspe:0.340415\ttrain-rmspe:0.356071\n",
      "[334]\teval-rmspe:0.339532\ttrain-rmspe:0.355325\n",
      "[335]\teval-rmspe:0.338717\ttrain-rmspe:0.354643\n",
      "[336]\teval-rmspe:0.337903\ttrain-rmspe:0.353967\n",
      "[337]\teval-rmspe:0.337057\ttrain-rmspe:0.353256\n",
      "[338]\teval-rmspe:0.336251\ttrain-rmspe:0.352577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[339]\teval-rmspe:0.335444\ttrain-rmspe:0.351912\n",
      "[340]\teval-rmspe:0.334715\ttrain-rmspe:0.351309\n",
      "[341]\teval-rmspe:0.333935\ttrain-rmspe:0.35066\n",
      "[342]\teval-rmspe:0.333203\ttrain-rmspe:0.350051\n",
      "[343]\teval-rmspe:0.332471\ttrain-rmspe:0.349441\n",
      "[344]\teval-rmspe:0.331811\ttrain-rmspe:0.348901\n",
      "[345]\teval-rmspe:0.331157\ttrain-rmspe:0.348374\n",
      "[346]\teval-rmspe:0.33049\ttrain-rmspe:0.347833\n",
      "[347]\teval-rmspe:0.329852\ttrain-rmspe:0.347315\n",
      "[348]\teval-rmspe:0.329235\ttrain-rmspe:0.346825\n",
      "[349]\teval-rmspe:0.328631\ttrain-rmspe:0.346356\n",
      "[350]\teval-rmspe:0.328029\ttrain-rmspe:0.345854\n",
      "[351]\teval-rmspe:0.327439\ttrain-rmspe:0.345401\n",
      "[352]\teval-rmspe:0.326823\ttrain-rmspe:0.3449\n",
      "[353]\teval-rmspe:0.326249\ttrain-rmspe:0.344462\n",
      "[354]\teval-rmspe:0.325712\ttrain-rmspe:0.344054\n",
      "[355]\teval-rmspe:0.32518\ttrain-rmspe:0.343644\n",
      "[356]\teval-rmspe:0.324681\ttrain-rmspe:0.343269\n",
      "[357]\teval-rmspe:0.324207\ttrain-rmspe:0.342903\n",
      "[358]\teval-rmspe:0.323763\ttrain-rmspe:0.342578\n",
      "[359]\teval-rmspe:0.323275\ttrain-rmspe:0.342205\n",
      "[360]\teval-rmspe:0.322828\ttrain-rmspe:0.341869\n",
      "[361]\teval-rmspe:0.322422\ttrain-rmspe:0.341568\n",
      "[362]\teval-rmspe:0.322035\ttrain-rmspe:0.341279\n",
      "[363]\teval-rmspe:0.321612\ttrain-rmspe:0.340943\n",
      "[364]\teval-rmspe:0.321168\ttrain-rmspe:0.340624\n",
      "[365]\teval-rmspe:0.320788\ttrain-rmspe:0.340362\n",
      "[366]\teval-rmspe:0.320413\ttrain-rmspe:0.340098\n",
      "[367]\teval-rmspe:0.320033\ttrain-rmspe:0.33983\n",
      "[368]\teval-rmspe:0.319704\ttrain-rmspe:0.3396\n",
      "[369]\teval-rmspe:0.319339\ttrain-rmspe:0.339357\n",
      "[370]\teval-rmspe:0.318979\ttrain-rmspe:0.339095\n",
      "[371]\teval-rmspe:0.3187\ttrain-rmspe:0.33891\n",
      "[372]\teval-rmspe:0.318383\ttrain-rmspe:0.338702\n",
      "[373]\teval-rmspe:0.318096\ttrain-rmspe:0.338521\n",
      "[374]\teval-rmspe:0.317814\ttrain-rmspe:0.338335\n",
      "[375]\teval-rmspe:0.317556\ttrain-rmspe:0.338178\n",
      "[376]\teval-rmspe:0.31725\ttrain-rmspe:0.337958\n",
      "[377]\teval-rmspe:0.31693\ttrain-rmspe:0.337689\n",
      "[378]\teval-rmspe:0.316644\ttrain-rmspe:0.337483\n",
      "[379]\teval-rmspe:0.316449\ttrain-rmspe:0.337399\n",
      "[380]\teval-rmspe:0.316273\ttrain-rmspe:0.337315\n",
      "[381]\teval-rmspe:0.316036\ttrain-rmspe:0.337181\n",
      "[382]\teval-rmspe:0.315822\ttrain-rmspe:0.337081\n",
      "[383]\teval-rmspe:0.315634\ttrain-rmspe:0.336985\n",
      "[384]\teval-rmspe:0.315407\ttrain-rmspe:0.336842\n",
      "[385]\teval-rmspe:0.315211\ttrain-rmspe:0.336747\n",
      "[386]\teval-rmspe:0.315077\ttrain-rmspe:0.336695\n",
      "[387]\teval-rmspe:0.31486\ttrain-rmspe:0.336568\n",
      "[388]\teval-rmspe:0.314726\ttrain-rmspe:0.336508\n",
      "[389]\teval-rmspe:0.314541\ttrain-rmspe:0.336409\n",
      "[390]\teval-rmspe:0.314396\ttrain-rmspe:0.336347\n",
      "[391]\teval-rmspe:0.314235\ttrain-rmspe:0.336289\n",
      "[392]\teval-rmspe:0.314054\ttrain-rmspe:0.336204\n",
      "[393]\teval-rmspe:0.31394\ttrain-rmspe:0.336144\n",
      "[394]\teval-rmspe:0.313855\ttrain-rmspe:0.336139\n",
      "[395]\teval-rmspe:0.313778\ttrain-rmspe:0.336138\n",
      "[396]\teval-rmspe:0.313635\ttrain-rmspe:0.336088\n",
      "[397]\teval-rmspe:0.313494\ttrain-rmspe:0.336019\n",
      "[398]\teval-rmspe:0.313397\ttrain-rmspe:0.336005\n",
      "[399]\teval-rmspe:0.313301\ttrain-rmspe:0.335984\n",
      "[400]\teval-rmspe:0.313216\ttrain-rmspe:0.335976\n",
      "[401]\teval-rmspe:0.313077\ttrain-rmspe:0.335911\n",
      "[402]\teval-rmspe:0.312999\ttrain-rmspe:0.335908\n",
      "[403]\teval-rmspe:0.31297\ttrain-rmspe:0.335951\n",
      "[404]\teval-rmspe:0.312944\ttrain-rmspe:0.335987\n",
      "[405]\teval-rmspe:0.312829\ttrain-rmspe:0.33589\n",
      "[406]\teval-rmspe:0.31281\ttrain-rmspe:0.335939\n",
      "[407]\teval-rmspe:0.312722\ttrain-rmspe:0.335945\n",
      "[408]\teval-rmspe:0.312714\ttrain-rmspe:0.336005\n",
      "[409]\teval-rmspe:0.312667\ttrain-rmspe:0.336036\n",
      "[410]\teval-rmspe:0.312612\ttrain-rmspe:0.33604\n",
      "[411]\teval-rmspe:0.312553\ttrain-rmspe:0.336064\n",
      "[412]\teval-rmspe:0.312533\ttrain-rmspe:0.336106\n",
      "[413]\teval-rmspe:0.312541\ttrain-rmspe:0.336182\n",
      "[414]\teval-rmspe:0.312577\ttrain-rmspe:0.336271\n",
      "[415]\teval-rmspe:0.312608\ttrain-rmspe:0.336341\n",
      "[416]\teval-rmspe:0.312513\ttrain-rmspe:0.336311\n",
      "[417]\teval-rmspe:0.312488\ttrain-rmspe:0.336362\n",
      "[418]\teval-rmspe:0.3124\ttrain-rmspe:0.336341\n",
      "[419]\teval-rmspe:0.312401\ttrain-rmspe:0.336413\n",
      "[420]\teval-rmspe:0.312462\ttrain-rmspe:0.336526\n",
      "[421]\teval-rmspe:0.312524\ttrain-rmspe:0.33664\n",
      "[422]\teval-rmspe:0.312475\ttrain-rmspe:0.336662\n",
      "[423]\teval-rmspe:0.312531\ttrain-rmspe:0.33678\n",
      "[424]\teval-rmspe:0.312585\ttrain-rmspe:0.3369\n",
      "[425]\teval-rmspe:0.312236\ttrain-rmspe:0.336622\n",
      "[426]\teval-rmspe:0.312315\ttrain-rmspe:0.33676\n",
      "[427]\teval-rmspe:0.312399\ttrain-rmspe:0.336898\n",
      "[428]\teval-rmspe:0.312452\ttrain-rmspe:0.337002\n",
      "[429]\teval-rmspe:0.312431\ttrain-rmspe:0.33706\n",
      "[430]\teval-rmspe:0.3125\ttrain-rmspe:0.337183\n",
      "[431]\teval-rmspe:0.312586\ttrain-rmspe:0.337326\n",
      "[432]\teval-rmspe:0.312622\ttrain-rmspe:0.337413\n",
      "[433]\teval-rmspe:0.312712\ttrain-rmspe:0.337552\n",
      "[434]\teval-rmspe:0.312764\ttrain-rmspe:0.337664\n",
      "[435]\teval-rmspe:0.312762\ttrain-rmspe:0.337738\n",
      "[436]\teval-rmspe:0.312835\ttrain-rmspe:0.337876\n",
      "[437]\teval-rmspe:0.312931\ttrain-rmspe:0.338014\n",
      "[438]\teval-rmspe:0.313017\ttrain-rmspe:0.338139\n",
      "[439]\teval-rmspe:0.313112\ttrain-rmspe:0.338274\n",
      "[440]\teval-rmspe:0.313204\ttrain-rmspe:0.338452\n",
      "[441]\teval-rmspe:0.313299\ttrain-rmspe:0.338589\n",
      "[442]\teval-rmspe:0.313291\ttrain-rmspe:0.338628\n",
      "[443]\teval-rmspe:0.313237\ttrain-rmspe:0.338655\n",
      "[444]\teval-rmspe:0.31334\ttrain-rmspe:0.338805\n",
      "[445]\teval-rmspe:0.313216\ttrain-rmspe:0.338767\n",
      "[446]\teval-rmspe:0.313154\ttrain-rmspe:0.338726\n",
      "[447]\teval-rmspe:0.313203\ttrain-rmspe:0.338825\n",
      "[448]\teval-rmspe:0.313054\ttrain-rmspe:0.338762\n",
      "[449]\teval-rmspe:0.313141\ttrain-rmspe:0.338898\n",
      "[450]\teval-rmspe:0.313176\ttrain-rmspe:0.338975\n",
      "[451]\teval-rmspe:0.313141\ttrain-rmspe:0.338994\n",
      "[452]\teval-rmspe:0.313132\ttrain-rmspe:0.33905\n",
      "[453]\teval-rmspe:0.313231\ttrain-rmspe:0.339203\n",
      "[454]\teval-rmspe:0.31325\ttrain-rmspe:0.339282\n",
      "[455]\teval-rmspe:0.313274\ttrain-rmspe:0.339336\n",
      "[456]\teval-rmspe:0.31335\ttrain-rmspe:0.339456\n",
      "[457]\teval-rmspe:0.31339\ttrain-rmspe:0.33955\n",
      "[458]\teval-rmspe:0.313474\ttrain-rmspe:0.339678\n",
      "[459]\teval-rmspe:0.313587\ttrain-rmspe:0.339814\n",
      "[460]\teval-rmspe:0.313661\ttrain-rmspe:0.339927\n",
      "[461]\teval-rmspe:0.313667\ttrain-rmspe:0.33994\n",
      "[462]\teval-rmspe:0.313614\ttrain-rmspe:0.339947\n",
      "[463]\teval-rmspe:0.313731\ttrain-rmspe:0.340096\n",
      "[464]\teval-rmspe:0.313654\ttrain-rmspe:0.340075\n",
      "[465]\teval-rmspe:0.313672\ttrain-rmspe:0.340154\n",
      "[466]\teval-rmspe:0.313554\ttrain-rmspe:0.3401\n",
      "[467]\teval-rmspe:0.313553\ttrain-rmspe:0.34016\n",
      "[468]\teval-rmspe:0.313596\ttrain-rmspe:0.340258\n",
      "[469]\teval-rmspe:0.313664\ttrain-rmspe:0.340354\n",
      "[470]\teval-rmspe:0.313667\ttrain-rmspe:0.340421\n",
      "[471]\teval-rmspe:0.313754\ttrain-rmspe:0.340544\n",
      "[472]\teval-rmspe:0.313802\ttrain-rmspe:0.34063\n",
      "[473]\teval-rmspe:0.313926\ttrain-rmspe:0.340785\n",
      "[474]\teval-rmspe:0.313929\ttrain-rmspe:0.340826\n",
      "[475]\teval-rmspe:0.314044\ttrain-rmspe:0.340979\n",
      "[476]\teval-rmspe:0.314008\ttrain-rmspe:0.340968\n",
      "[477]\teval-rmspe:0.314017\ttrain-rmspe:0.341051\n",
      "[478]\teval-rmspe:0.31414\ttrain-rmspe:0.341196\n",
      "[479]\teval-rmspe:0.314174\ttrain-rmspe:0.341236\n",
      "[480]\teval-rmspe:0.314145\ttrain-rmspe:0.341231\n",
      "[481]\teval-rmspe:0.314172\ttrain-rmspe:0.341296\n",
      "[482]\teval-rmspe:0.314207\ttrain-rmspe:0.341386\n",
      "[483]\teval-rmspe:0.314324\ttrain-rmspe:0.341526\n",
      "[484]\teval-rmspe:0.314369\ttrain-rmspe:0.341626\n",
      "[485]\teval-rmspe:0.314405\ttrain-rmspe:0.3417\n",
      "[486]\teval-rmspe:0.314455\ttrain-rmspe:0.341805\n",
      "[487]\teval-rmspe:0.314571\ttrain-rmspe:0.341949\n",
      "[488]\teval-rmspe:0.31458\ttrain-rmspe:0.342005\n",
      "[489]\teval-rmspe:0.314668\ttrain-rmspe:0.342059\n",
      "[490]\teval-rmspe:0.314688\ttrain-rmspe:0.342136\n",
      "[491]\teval-rmspe:0.314613\ttrain-rmspe:0.342096\n",
      "[492]\teval-rmspe:0.31467\ttrain-rmspe:0.342199\n",
      "[493]\teval-rmspe:0.314769\ttrain-rmspe:0.342323\n",
      "[494]\teval-rmspe:0.314749\ttrain-rmspe:0.342333\n",
      "[495]\teval-rmspe:0.314725\ttrain-rmspe:0.342333\n",
      "[496]\teval-rmspe:0.314687\ttrain-rmspe:0.342339\n",
      "[497]\teval-rmspe:0.314745\ttrain-rmspe:0.34243\n",
      "[498]\teval-rmspe:0.314839\ttrain-rmspe:0.342516\n",
      "[499]\teval-rmspe:0.314958\ttrain-rmspe:0.342659\n",
      "[500]\teval-rmspe:0.315036\ttrain-rmspe:0.342764\n",
      "[501]\teval-rmspe:0.314934\ttrain-rmspe:0.342694\n",
      "[502]\teval-rmspe:0.314909\ttrain-rmspe:0.342696\n",
      "[503]\teval-rmspe:0.314933\ttrain-rmspe:0.342737\n",
      "[504]\teval-rmspe:0.315016\ttrain-rmspe:0.342834\n",
      "[505]\teval-rmspe:0.31512\ttrain-rmspe:0.342928\n",
      "Stopping. Best iteration:\n",
      "[405]\teval-rmspe:0.312829\ttrain-rmspe:0.33589\n",
      "\n",
      "0.315119522982\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>...</th>\n",
       "      <th>promomar</th>\n",
       "      <th>promoapr</th>\n",
       "      <th>promomay</th>\n",
       "      <th>promojun</th>\n",
       "      <th>promojul</th>\n",
       "      <th>promoaug</th>\n",
       "      <th>promosep</th>\n",
       "      <th>promooct</th>\n",
       "      <th>promonov</th>\n",
       "      <th>promodec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.732569</td>\n",
       "      <td>0.837651</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>0.082509</td>\n",
       "      <td>1.119016</td>\n",
       "      <td>0</td>\n",
       "      <td>1.968221</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.729461</td>\n",
       "      <td>0.837651</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>0.082509</td>\n",
       "      <td>1.119016</td>\n",
       "      <td>0</td>\n",
       "      <td>1.968221</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.726352</td>\n",
       "      <td>0.837651</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>0.082509</td>\n",
       "      <td>1.119016</td>\n",
       "      <td>0</td>\n",
       "      <td>1.968221</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.723243</td>\n",
       "      <td>0.837651</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>0.082509</td>\n",
       "      <td>1.119016</td>\n",
       "      <td>0</td>\n",
       "      <td>1.968221</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.720134</td>\n",
       "      <td>0.837651</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>0.082509</td>\n",
       "      <td>1.119016</td>\n",
       "      <td>0</td>\n",
       "      <td>1.968221</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Store  DayOfWeek        Date  Sales  Customers      Open     Promo  \\\n",
       "0 -1.732569   0.837651  2015-07-31   5263        555  0.082509  1.119016   \n",
       "1 -1.729461   0.837651  2015-07-31   6064        625  0.082509  1.119016   \n",
       "2 -1.726352   0.837651  2015-07-31   8314        821  0.082509  1.119016   \n",
       "3 -1.723243   0.837651  2015-07-31  13995       1498  0.082509  1.119016   \n",
       "4 -1.720134   0.837651  2015-07-31   4822        559  0.082509  1.119016   \n",
       "\n",
       "   StateHoliday  SchoolHoliday  StoreType    ...     promomar  promoapr  \\\n",
       "0             0       1.968221          2    ...            0         0   \n",
       "1             0       1.968221          0    ...            0         1   \n",
       "2             0       1.968221          0    ...            0         1   \n",
       "3             0       1.968221          2    ...            0         0   \n",
       "4             0       1.968221          0    ...            0         0   \n",
       "\n",
       "   promomay  promojun  promojul  promoaug  promosep  promooct  promonov  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         1         0         0         1         0   \n",
       "2         0         0         1         0         0         1         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   promodec  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"=> 载入数据中...\"\n",
    "train,test,features,features_non_numeric = load_data()\n",
    "print \"=> 处理数据与特征工程...\"\n",
    "train,test,features,features_non_numeric = process_data(train,test,features,features_non_numeric)\n",
    "print \"=> 使用XGBoost建模...\"\n",
    "XGB_native(train,test,features,features_non_numeric)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
